Automatically generated by Mendeley Desktop 1.17.9
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Zang2013,
abstract = {Collecting massive commonsense knowledge (CSK) for commonsense reasoning has been a long time standing challenge within artificial intelligence research. Numerous methods and systems for acquiring CSK have been developed to overcome the knowledge acquisition bottleneck. Although some specific commonsense reasoning tasks have been presented to allow researchers to measure and compare the performance of their CSK systems, we compare them at a higher level from the following aspects: CSK acquisition task (what CSK is acquired from where), technique used (how can CSK be acquired), and CSK evaluation methods (how to evaluate the acquired CSK). In this survey, we first present a categorization of CSK acquisition systems and the great challenges in the field. Then, we review and compare the CSK acquisition systems in detail. Finally, we conclude the current progress in this field and explore some promising future research issues.},
annote = {Good survey for related work. Main conclusions:

- Mostly measuring correctness of the kwnowledge and efficiency of collecting. Missing good evaluation methiods.
- Kako usefulness?


related work:
[46] = rewards user when he answers (Prebral)
[19] = answers in NL (Prebral)
[21] = automatically transform NL into the formal representation
[22,26,27] = Infer new knowledge after get some knowledge - !!my idea-need to check
[30] Interactive KA approach
[33,34] = Open Information Extraction - To inspire further work !!important to check!!
[37,38,54] = CYC for Q/A already!
[18] = Naucil so se lessions while hand coding Cyc
[58]Kraken, [59] UIIA, [27] Predicate Populator = CC Competitors
[37]= Cyc KA using pre-existing knowledge !!!My idea as well
[60] = generate rules automatically
[10] = Commercial Cyc based QA

[66] = SmartCalendar, ThoughtTreasure app
!!![67,28, 82] Verbosity game to fill OMCS knowledge
[30] 20 questions game - Janez's idea as side CC thing

[76] ConceptNet-3 says it does NL to logic, logic to NL - what CC needs
[72, 82] = Games with a Purpose
[32] - ideal, complete CSKB
[31] - Virtual pet game

[48, 23] Evaluation, some comparison to Cyc
[38] Learning by reading -Cyc stuff as well
[21] - Knowledge Gap problem
[30] - guide users to enter the missing knowledge

[32] Liner Regression to measure new knowledge each day},
author = {Zang, Liang-Jun and Cao, Cong and Cao, Ya-Nan and Wu, Yu-Ming and CAO, Cun-Gen},
doi = {10.1007/s11390-013-1369-6},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zang et al. - 2013 - A Survey of Commonsense Knowledge Acquisition.pdf:pdf},
issn = {1000-9000},
journal = {Journal of Computer Science and Technology},
keywords = {KA,Survey,commonsense knowledge,knowledge acquisition,knowledge representation and reasoning},
mendeley-tags = {KA,Survey},
month = {jul},
number = {4},
pages = {689--719},
title = {{A Survey of Commonsense Knowledge Acquisition}},
url = {http://link.springer.com/10.1007/s11390-013-1369-6},
volume = {28},
year = {2013}
}
