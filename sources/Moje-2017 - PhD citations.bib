Automatically generated by Mendeley Desktop 1.17.10
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Mamei2010,
abstract = {Recent mobile computing applications try to automatically identify the places visited by the user from a log of GPS readings. Such applications reverse geocode the GPS data to discover the actual places shops, restaurants, etc. where the user has been. Unfortunately, because of GPS errors, the actual addresses and businesses being visited cannot be extracted unambiguously and often only a list of candidate places can be obtained. Commonsense reasoning can notably help the disambiguation process by invalidating some unlikely findings e.g., a user visiting a cinema in the morning. This paper illustrates the use of Cyc-an artificial intelligence system comprising a database of commonsense knowledge-to improve automatic place identification. Cyc allows to probabilistically rank the list of candidate places in consideration of the commonsense likelihood of that place being actually visited on the basis of the user profile, the time of the day, what happened before, and so forth. The system has been evaluated using real data collected from a mobile computing application.},
author = {Mamei, Marco},
doi = {10.4018/jhcr.2010040103},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/cyc-whereabouts.pdf:pdf},
journal = {International Journal of Handheld Computing Research},
keywords = {commonsense,location-based services,mobile applications},
number = {2},
pages = {36--53},
title = {{Applying Commonsense Reasoning to Place Identification}},
url = {http://dx.doi.org/10.4018/jhcr.2010040103},
volume = {1},
year = {2010}
}
@phdthesis{Eslick2006,
abstract = {Acquiring and representing the large body of “common sense” knowledge underlying ordinary human reasoning and communication is a long standing problem in the field of artificial intelligence. This thesis will address the question whether a significant quantity of this knowledge may be acquired by mining natural language content on the Web. Specifically, this thesis emphasizes the representation of knowledge in the form of binary semantic relationships, such as cause, effect, intent, and time, among natural language phrases. The central hypothesis is that seed knowledge collected from volunteers enables automated acquisition of this knowledge from a large, unannotated, general corpus like the Web. A text mining system, ConceptMiner, was developed to evaluate this hypothesis. ConceptMiner leverages web search engines, Information Extraction tech- niques and the ConceptNet toolkit to analyze Web content for textual evidence indi- cating common sense relationships. Experiments are reported for three semantic relation classes: desire, effect, and capability. A Pointwise Mutual Infomation measure computed from Web hit counts is demonstrated to filter general common sense from instance knowledge true only in specific circumstances. A semantic distance metric is introduced which significantly reduces negative instances from the extracted hypotheses. The results confirm that significant relational common sense knowledge exists on the Web and provides evidence that the algorithms employed by ConceptMiner can extract this knowledge with a precision approaching that provided by human subjects.},
author = {Eslick, Ian Scott},
booktitle = {MIT Mater Thesis},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/Master thesis - Eslick - Searching for Commonsense.pdf:pdf},
title = {{Searching for Commonsense}},
year = {2006}
}
@article{Singh2002b,
abstract = {The Open Mind Common Sense project is an attempt to construct a database of commonsense knowledge through the collaboration of a distributed community of thousands of non-expert netizens. We give an overview of the project, describe our knowledge acquisition and representation strategy of using natural language rather than formal logic, and demonstrate this strategy with a search engine application that employs simple commonsense reasoning to reformulate problem queries into more effective solution queries.},
author = {Singh, Push},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh - 2002 - The Public Acquisition of Commonsense Knowledge Push Singh The Diversity of Commonsense Knowledge.pdf:pdf},
journal = {AAAI Spring Symposium: Acquiring (and Using) Linguistic (and World) Knowledge for Information Access},
pages = {47--53},
title = {{The Public Acquisition of Commonsense Knowledge Push Singh The Diversity of Commonsense Knowledge}},
url = {http://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-09/SS02-09-011.pdf},
year = {2002}
}
@inproceedings{Speer2007,
author = {Speer, Robert},
booktitle = {Proceedings of the Workshop on Common Sense and Interactive Applications},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Speer - 2007 - Open mind commons An inquisitive approach to learning common sense.pdf:pdf},
keywords = {analogy,commonsense,feedback,inference,knowledge acquisition},
title = {{Open mind commons: An inquisitive approach to learning common sense}},
url = {http://www.fatih.edu.tr/{~}hugur/inquisitive/Open Mind Commons An Inquisitive Approach to.PDF},
year = {2007}
}
@article{Quinlan1995,
abstract = {FOIL is a first-order learning system that uses information in a collection of relations to construct theories expressed in a dialect of Prolog. This paper provides an overview of the principal ideas and methods used in the current version of the system, including two recent additions. We present examples of tasks tackled by FOIL and of systems that adapt and extend its approach.},
author = {J.R., Quinlan and R.M., Cameron-Jones},
doi = {10.1007/BF03037228},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/J.R., R.M. - 1997 - Induction of Logic Programs FOIL and related systems.pdf:pdf},
journal = {New Generation Computing},
number = {3},
pages = {287--312},
title = {{Induction of Logic Programs: FOIL and related systems}},
url = {https://doi.org/10.1007/BF03037228},
volume = {13},
year = {1997}
}
@article{Weizenbaum1966,
author = {Weizenbaum, Joseph},
doi = {10.1145/365153.365168},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Weizenbaum - 1966 - ELIZA--A Computer Program For the Study of Natural Language Communication Between Man and Machine.pdf:pdf},
isbn = {00010782},
issn = {00010782},
journal = {Communication of the ACM},
number = {1},
pages = {36--45},
pmid = {12345678},
title = {{ELIZA--A Computer Program For the Study of Natural Language Communication Between Man and Machine}},
volume = {9},
year = {1966}
}
@inproceedings{VonAhn2006a,
author = {Ahn, Luis Von and Kedia, Mihir and Blum, Manuel},
booktitle = {Proceedings of the SIGCHI conference on Human Factors in computing systems},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahn, Kedia, Blum - 2006 - Verbosity A Game for Collecting Common-Sense Facts.pdf:pdf},
isbn = {1595931783},
pages = {75--78},
title = {{Verbosity : A Game for Collecting Common-Sense Facts}},
year = {2006}
}
@article{Speer2009,
abstract = {We present a game-based interface for acquiring common sense knowledge. In addition to being interactive and entertaining, our interface guides the knowledge acquisition process to learn about the most salient characteristics of a particular concept. We use statistical classification methods to discover the most informative characteristics in the Open Mind Common Sense knowledge base, and use these characteristics to play a game of 20 Questions with the user. Our interface also allows users to enter knowledge more quickly than a more traditional knowledge-acquisition interface. An evaluation showed that users enjoyed the game and that it increased the speed of knowledge acquisition.},
author = {Speer, Robert and Krishnamurthy, Jayant and Havasi, Catherine and Smith, Dustin and Lieberman, Henry and Arnold, Kenneth},
doi = {10.1145/1502650.1502672},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Speer et al. - 2009 - An interface for targeted collection of common sense knowledge using a mixture model.pdf:pdf},
isbn = {9781605583310},
journal = {Proceedings of the 14th International Conference on Intelligent User Interfaces},
pages = {137--146},
title = {{An interface for targeted collection of common sense knowledge using a mixture model}},
year = {2009}
}
@article{Medelyan2008,
abstract = {Integration of ontologies begins with establishing mappings between their concept entries. We map categories from the largest manually-built ontology, Cyc, onto Wikipedia articles describing corresponding concepts. Our method draws both on Wikipedias rich but chaotic hyperlink structure and Cycs carefully defined taxonomic and common-sense knowledge. On 9,333 manual alignments by one person, we achieve an F-measure of 90{\%}; on 100 alignments by six human subjects the average agreement of the method with the subject is close to their agreement with each other. We cover 62.8{\%} of Cyc categories relating to common-sense knowledge and discuss what further information might be added to Cyc given this substantial new alignment},
author = {Medelyan, Olena and Legg, Catherine},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/CycWiki.pdf:pdf},
isbn = {9781577353836},
journal = {Proceedings of the WIKIAI Wikipedia and AI Workshop at the AAAI},
keywords = {Technical Report WS-08-15},
pages = {13--18},
title = {{Integrating Cyc and Wikipedia: Folksonomy meets rigorously defined common-sense}},
url = {http://www.aaai.org/Papers/Workshops/2008/WS-08-15/WS08-15-003.pdf},
volume = {8},
year = {2008}
}
@article{VonAhn2008,
abstract = {MANY TASKS ARE trivial for humans but continue to challenge even the most sophisticated computer programs. Traditional computational approaches to solving such problems focus on improving artificial- intelligence algorithms. Here, we advocate a different approach: the constructive channeling of human brainpower through computer games. Toward this goal, we present general design principles for the development and evaluation of a class of games we call “games with a purpose,” or GWAPs, in which people, as a side effect of playing, perform tasks computers are unable to perform. The Entertainment Software Association (www. theesa.com/facts/gamer{\_}data.php) has reported that more than 200 million hours are spent each day playing computer and video games in the U.S. Indeed, by age 21, the average American has spent more than 10,000 hours playing such games - equivalent to 5 years of working a full-time job 40 hours per week.},
author = {von Ahn, Luis and Dabbish, Laura},
doi = {10.1145/1378704.1378719},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/von Ahn, Dabbish - 2008 - Designing games with a purpose.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
number = {8},
pages = {57},
pmid = {20192282},
title = {{Designing games with a purpose}},
volume = {51},
year = {2008}
}
@inproceedings{Witbrock2003UIA,
address = {Acapulco, Mexico},
author = {Witbrock, Michael and Baxter, David and Curtis, Jon and Schneider, Dave and Kahlert, Robert Christian and Miraglia, Pierluigi and Wagner, Peter and Panton, Kathy and Matthews, Gavin and Vizedom, Amanda},
booktitle = {Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Witbrock et al. - 2003 - An Interactive Dialogue System for Knowledge Acquisition in Cyc.pdf:pdf},
title = {{An Interactive Dialogue System for Knowledge Acquisition in Cyc}},
year = {2003}
}
@article{Speer2016,
abstract = {Machine learning about language can be improved by supplying it with specific knowledge and sources of external information. We present here a new version of the linked open data resource ConceptNet that is particularly well suited to be used with modern NLP techniques such as word embeddings. ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert-created resources, crowd-sourcing, and games with a purpose. It is designed to represent the general knowledge involved in understanding language, improving natural language applications by allowing the application to better understand the meanings behind the words people use. When ConceptNet is combined with word embeddings acquired from distributional semantics (such as word2vec), it provides applications with understanding that they would not acquire from distributional semantics alone, nor from narrower resources such as WordNet or DBPedia. We demonstrate this with state-of-the-art results on intrinsic evaluations of word relatedness that translate into improvements on applications of word vectors, including solving SAT-style analogies.},
archivePrefix = {arXiv},
arxivId = {1612.03975},
author = {Speer, Robert and Chin, Joshua and Havasi, Catherine},
eprint = {1612.03975},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Speer, Chin, Havasi - 2016 - ConceptNet 5.5 An Open Multilingual Graph of General Knowledge.pdf:pdf},
number = {Singh 2002},
title = {{ConceptNet 5.5: An Open Multilingual Graph of General Knowledge}},
url = {http://arxiv.org/abs/1612.03975},
year = {2016}
}
@book{Mueller1999,
author = {Mueller, Erik T},
booktitle = {Computing Research Repository (CoRR)},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mueller - 1999 - A database and lexicon of scripts for ThoughtTreasure.pdf:pdf},
pages = {Article No. 0003004},
publisher = {CogPrints ID cog00000555 http://cogprints.soton.ac.uk},
title = {{A database and lexicon of scripts for ThoughtTreasure.}},
volume = {1999},
year = {1999}
}
@unpublished{Wallace2013,
author = {Wallace, Richard},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/93c8b058d8b219ac51097ed3b5d44cceda4174ae.html:html},
publisher = {Alice Foundation},
title = {{AIML 2.0 Draft Specification}},
url = {http://www.alicebot.org/style.pdf},
year = {2013}
}
@article{Martin1986,
author = {Martin, E and Riesbeck, I},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/Uniform Parsing and Inferencing for Learning.pdf:pdf},
journal = {Proceedings of AAAI-86},
pages = {257--261},
title = {{Uniform Parsing and Inferencing for Learning}},
year = {1986}
}
@article{Schubert2002,
abstract = {As one attack on the " knowledge acquisition bottleneck " , we are attempting to exploit a largely untapped source of general knowl-edge in texts, lying at a level beneath the explicit assertional con-tent. This knowledge consists of relationships implied to be possi-ble in the world, or, under certain conditions, implied to be normal or commonplace in the world. The goal of the work reported is to derive such general world knowledge (initially, from Penn Tree-bank corpora) in two stages: first, we derive general " possibilistic " propositions from noun phrases and clauses; then we try to derive stronger generalizations, based on the nature and statistical distri-bution of the possibilistic claims obtained in the first phase. Here we report preliminary results of the first phase, which indicate the feasibility of our project, and its likely limitations.},
author = {Schubert, Lenhart},
doi = {10.3115/1289189.1289263},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schubert - 2002 - Can we derive general world knowledge from texts.pdf:pdf},
journal = {Proceedings of the second international conference on Human Language Technology Research},
pages = {94},
title = {{Can we derive general world knowledge from texts?}},
url = {http://portal.acm.org/citation.cfm?doid=1289189.1289263},
year = {2002}
}
@article{Singh2002a,
abstract = {Abstract. Open Mind Common Sense is a knowledge acquisition system de- signed to acquire commonsense knowledge from the general public over the web. We describe and evaluate our first fielded system, which enabled the construction of a 450,000 assertion commonsense knowledge base. We then discuss how our second-generation system addresses weaknesses discovered in the first. The new system acquires facts, descriptions, and stories by allowing participants to construct and fill in natural language templates. It employs word-sense disambiguation and methods of clarifying entered knowledge, ana- logical inference to provide feedback, and allows participants to validate knowledge and in turn each other.},
annote = {Prebral Februarja 2016

Tle so probal ze s
- templati,
- feedbackom z reasoningom
- slab rule acquisition


Here they evaluate the previous article. 

OMCS1 v 2h letih. September 2000- Avgust 2002, so dobili 456.195 pieces of knowledge from 9296 people

Manual evaluation:
3245 unique items (1{\%} cele).
236 (7.3{\%}) discarded - needed other material
7 judges:
370 (12.3{\%}) = garbage
ostalo rated od 1 do 5


[8](2001) intergrated KA system 
[9] Constrained NL KA (pulldowns)
[10] subset of english which is restricted enough to be converted into the 1st order.
[11] Reasoning
[21] = methods for acquiring procedural knowledge
[22] scripts for coordinating changes in the db
[23] reflective architectures},
author = {Singh, Push and Lin, Thomas and Mueller, E.T. and Lim, G. and Perkins, T. and Zhu, W.L.},
doi = {10.1007/3-540-36124-3_77},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh et al. - 2002 - Open Mind Common Sense Knowledge acquisition from the general public.pdf:pdf},
isbn = {3540001069},
issn = {03029743},
journal = {Cooperative Information Systems Oct. 30-Nov. 1 2002},
keywords = {KA,Open mind},
mendeley-tags = {KA,Open mind},
pages = {1223--1237},
title = {{Open Mind Common Sense: Knowledge acquisition from the general public}},
url = {http://portal.acm.org/citation.cfm?id=646748.701499},
year = {2002}
}
@article{Wilcox2011,
author = {Wilcox, Bruce},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilcox - 2011 - Beyond Fa{\c{c}}ade Pattern Matching for Natural Language Applications.pdf:pdf},
journal = {Gamasutra},
keywords = {3d animation,3d modeling,3d studio max textures,3d technology,arcade development,artificial intelligence,cmp game media group,computer game developers conference,digital assets,digital entertainment,dreamcast development,free 3d models,free shaders,free textures,gamasutra exchange,game animation,game audio,game business,game design,game developer,game developer magazine,game developers conference,game development,game development software,game directory,game industry research,game jobs,game news,game producer,game programmer,game programming,game technology,independent game developers conference,new game,nintendo development,online game development,pc game,playstation 2,playstation development,ps2,videogame,virtual reality,xbox game},
pages = {1--5},
title = {{Beyond Fa{\c{c}}ade: Pattern Matching for Natural Language Applications}},
url = {http://www.gamasutra.com/view/feature/6305/beyond{\_}fa�ade{\_}pattern{\_}matching{\_}.php?page=1},
year = {2011}
}
@article{Wu2012,
abstract = {Knowledge is indispensable to understanding. The ongoing information explosion highlights the need to enable machines to better understand electronic text in human language. Much work has been devoted to creating universal ontologies or taxonomies for this purpose. However, none of the existing ontologies has the needed depth and breadth for “universal understanding”. In this paper, we present a universal, probabilistic taxonomy that is more comprehensive than any existing ones. It contains 2.7 million concepts harnessed automatically from a corpus of 1.68 billion web pages. Unlike traditional taxonomies that treat knowledge as black and white, it uses probabilities to model inconsistent, ambiguous and uncertain information it contains. We present details of how the taxonomy is constructed, its probabilistic modeling, and its potential applications in text understanding.},
author = {Wu, Wentao and Li, Hongsong and Wang, Haixun and Zhu, Kenny Q.},
doi = {10.1016/j.artint.2011.01.003},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/Probase.pdf:pdf},
isbn = {9781450312479},
issn = {00043702},
journal = {Proceedings of the 2012 ACM SIGMOD {\ldots}},
keywords = {knowledgebase,taxonomy,text understanding},
pages = {481--492},
title = {{Probase: A probabilistic taxonomy for text understanding}},
url = {http://dl.acm.org/citation.cfm?id=2213891},
year = {2012}
}
@inproceedings{Bollacker2008,
address = {New York, NY, USA},
author = {Bollacker, Kurt and Evans, Colin and Paritosh, Praveen and Sturge, Tim and Taylor, Jamie},
booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
doi = {10.1145/1376616.1376746},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bollacker et al. - 2008 - Freebase A Collaboratively Created Graph Database for Structuring Human Knowledge.pdf:pdf},
isbn = {978-1-60558-102-6},
keywords = {collaborative systems,semantic network,tuple store},
pages = {1247--1250},
publisher = {ACM},
series = {SIGMOD '08},
title = {{Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge}},
url = {http://doi.acm.org/10.1145/1376616.1376746},
year = {2008}
}
@techreport{Wilcox2012,
author = {Wilcox, Bruce and Wilcox, Sue},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilcox, Wilcox - 2012 - Winning the Loebner's.pdf:pdf},
institution = {Brilligunderstanding},
keywords = {artificial intelligence,chatbot,chatscript,conversation,natural language},
title = {{Winning the Loebner's}},
url = {http://brilligunderstanding.com/Winning.pdf},
year = {2012}
}
@article{Sabou2013,
abstract = {Novel social media collaboration platforms, such as games with a purpose and mechanised labour marketplaces, are increasingly used for enlisting large populations of non-experts in crowdsourced knowledge acquisition processes. Climate Quiz uses this paradigm for acquiring environmental domain knowledge from non-experts. The game's usage statistics and the quality of the produced data show that Climate Quiz has managed to attract a large number of players but noisy input data and task complexity led to low player engagement and suboptimal task throughput and data quality. To address these limitations, the authors propose embedding the game into a hybrid-genre workflow, which supplements the game with a set of tasks outsourced to micro-workers, thus leveraging the complementary nature of games with a purpose and mechanised labour platforms. Experimental evaluations suggest that such workflows are feasible and have positive effects on the game's enjoyment level and the quality of its output.},
author = {Sabou, Marta and Scharl, Arno and Michael, F{\"{o}}ls},
doi = {10.4018/ijswis.2013070102},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/NewCC/Crowdsourced Knowledge Acquisition.pdf:pdf},
issn = {1552-6283},
journal = {International Journal On Semantic Web and Information SystemsInternational Journal On Semantic Web and Information Systems},
keywords = {climate change,crowdflower,crowdsourcing,games with a purpose,knowledge acquisition,mechanised labour,workflow},
number = {3},
pages = {1},
title = {{Crowdsourced Knowledge Acquisition: Towards Hybrid-genre Workflows}},
volume = {9},
year = {2013}
}
@inproceedings{Etzioni2004,
author = {Etzioni, Oren and Popescu, Ana-maria and Weld, Daniel S and Downey, Doug and Yates, Alexander},
booktitle = {WWW 2004},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Etzioni et al. - 2004 - Web-Scale Information Extraction in KnowItAll ( Preliminary Results ).pdf:pdf},
keywords = {information extraction,mutual information,search},
title = {{Web-Scale Information Extraction in KnowItAll ( Preliminary Results )}},
year = {2004}
}
@inproceedings{Matuszek2006,
author = {Matuszek, Cynthia and Cabral, John and Witbrock, Michael and Deoliveira, John},
booktitle = {Proceedings of the 2006 AAAI Spring Symposium on Formalizing and Compiling Background Knowledge and Its Applications to Knowledge Representation and Question Answering},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Matuszek et al. - 2006 - An Introduction to the Syntax and Content of Cyc(2).pdf:pdf},
publisher = {AAAI Press},
title = {{An Introduction to the Syntax and Content of Cyc}},
year = {2006}
}
@inproceedings{Matuszek2006a,
author = {Matuszek, Cynthia and Cabral, John and Witbrock, Michael and Deoliveira, John},
booktitle = {Proceedings of the 2006 AAAI Spring Symposium on Formalizing and Compiling Background Knowledge and Its Applications to Knowledge Representation and Question Answering},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Matuszek et al. - 2006 - An Introduction to the Syntax and Content of Cyc(2).pdf:pdf},
publisher = {AAAI Press},
title = {{An Introduction to the Syntax and Content of Cyc}},
year = {2006}
}
@article{Lv2016,
abstract = {A personally semantic place is a space that is frequently visited by an individual user and carries important semantic meanings (e.g. home, work, etc.) to the user. Many location-aware applications could be greatly enhanced by the ability of automatic discovery of personally semantic places. The discovery of a user's personally semantic places involves obtaining the physical locations and semantic meanings of these places. In this paper, we propose approaches to address both of the problems. For the physical place extraction problem, a hierarchical clustering algorithm is proposed to firstly extract visit points from the GPS trajectories, and then clusters these visit points to form physical places. For the semantic place recognition problem, the temporal, spatial and sequential features in which the places have been visited are explored to categorize them into pre-defined types. An extensive set of experiments conducted based on a dataset of real-world GPS trajectories has demonstrated the effectiveness of the proposed approaches.},
annote = {- Interesting location based messaging reference [7]
- interesting location prediction system [8]},
author = {Lv, Mingqi and Chen, Ling and Xu, Zhenxing and Li, Yinglong and Chen, Gencai},
doi = {10.1016/j.neucom.2015.08.071},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lv et al. - 2016 - The discovery of personally semantic places based on trajectory data mining.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Location-aware computing,Place extraction,Place recognition,Trajectory data mining},
pages = {1142--1153},
publisher = {Elsevier},
title = {{The discovery of personally semantic places based on trajectory data mining}},
url = {http://dx.doi.org/10.1016/j.neucom.2015.08.071},
volume = {173},
year = {2016}
}
@inproceedings{Bradesko2012,
author = {Brade{\v{s}}ko, Luka and Mladeni{\'{c}}, Dunja},
booktitle = {Proceedings of Slovenian Language Technologies Society Eighth Conference of Language Technologies},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brade{\v{s}}ko, Mladeni{\'{c}} - 2012 - A Survey of Chabot Systems through a Loebner Prize Competition.pdf:pdf},
isbn = {ISBN 978-961-264-048-4},
pages = {34--37},
title = {{A Survey of Chabot Systems through a Loebner Prize Competition}},
year = {2012}
}
@article{Zang2013,
abstract = {Collecting massive commonsense knowledge (CSK) for commonsense reasoning has been a long time standing challenge within artificial intelligence research. Numerous methods and systems for acquiring CSK have been developed to overcome the knowledge acquisition bottleneck. Although some specific commonsense reasoning tasks have been presented to allow researchers to measure and compare the performance of their CSK systems, we compare them at a higher level from the following aspects: CSK acquisition task (what CSK is acquired from where), technique used (how can CSK be acquired), and CSK evaluation methods (how to evaluate the acquired CSK). In this survey, we first present a categorization of CSK acquisition systems and the great challenges in the field. Then, we review and compare the CSK acquisition systems in detail. Finally, we conclude the current progress in this field and explore some promising future research issues.},
annote = {Good survey for related work. Main conclusions:

- Mostly measuring correctness of the kwnowledge and efficiency of collecting. Missing good evaluation methiods.
- Kako usefulness?


related work:
[46] = rewards user when he answers (Prebral)
[19] = answers in NL (Prebral)
[21] = automatically transform NL into the formal representation
[22,26,27] = Infer new knowledge after get some knowledge - !!my idea-need to check
[30] Interactive KA approach
[33,34] = Open Information Extraction - To inspire further work !!important to check!!
[37,38,54] = CYC for Q/A already!
[18] = Naucil so se lessions while hand coding Cyc
[58]Kraken, [59] UIIA, [27] Predicate Populator = CC Competitors
[37]= Cyc KA using pre-existing knowledge !!!My idea as well
[60] = generate rules automatically
[10] = Commercial Cyc based QA

[66] = SmartCalendar, ThoughtTreasure app
!!![67,28, 82] Verbosity game to fill OMCS knowledge
[30] 20 questions game - Janez's idea as side CC thing

[76] ConceptNet-3 says it does NL to logic, logic to NL - what CC needs
[72, 82] = Games with a Purpose
[32] - ideal, complete CSKB
[31] - Virtual pet game

[48, 23] Evaluation, some comparison to Cyc
[38] Learning by reading -Cyc stuff as well
[21] - Knowledge Gap problem
[30] - guide users to enter the missing knowledge

[32] Liner Regression to measure new knowledge each day},
author = {Zang, Liang-Jun and Cao, Cong and Cao, Ya-Nan and Wu, Yu-Ming and CAO, Cun-Gen},
doi = {10.1007/s11390-013-1369-6},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zang et al. - 2013 - A Survey of Commonsense Knowledge Acquisition.pdf:pdf},
issn = {1000-9000},
journal = {Journal of Computer Science and Technology},
keywords = {KA,Survey,commonsense knowledge,knowledge acquisition,knowledge representation and reasoning},
mendeley-tags = {KA,Survey},
month = {jul},
number = {4},
pages = {689--719},
title = {{A Survey of Commonsense Knowledge Acquisition}},
url = {http://link.springer.com/10.1007/s11390-013-1369-6},
volume = {28},
year = {2013}
}
@article{Lenat1995,
author = {Lenat, Douglas Bruce},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lenat - 1995 - Cyc A Large-Scale Investment in Knowledge Infrastructure.pdf:pdf},
journal = {Communications of the ACM},
number = {22},
title = {{Cyc: A Large-Scale Investment in Knowledge Infrastructure}},
volume = {38},
year = {1995}
}
@inproceedings{Mahdisoltani2015,
author = {Demner-Fushman, Dina and Chapman, Wendy W. and McDonald, Clement J. and Abe, Shuya and Inui, Kentaro and Matsumoto, Yuji and Nikfarjam, Azadeh and Emadzadeh, Ehsan and Gonzalez, Graciela and Lubiao, Li and Yinsheng, Zhang and Huilin, Wang and Chang, Yung Chun and Dai, Hong Jie and Wu, Johnny Chi Yang and Chen, Jian Ming and Tsai, Richard Tzong Han and Hsu, Wen Lian and Garrido, Guillermo and Pe{\~{n}}as, Anselmo and Cabaleiro, Bernardo and Rodrigo, {\'{A}}lvaro and Zhou, Li and Hripcsak, George and Kwon, Young-Su Kwon Young-Su and Kyung, Chong-Min Kyung Chong-Min and Ritter, Alan and Etzioni, Oren and Clark, Sam and Batal, Iyad and Harrison, James and Moerchen, Fabian and Biega, Joanna and Kuzey, E. and Suchanek, Fabian M F.M. Fm and Schilder, Frank and Habel, Christopher and Jindal, Prateek and Roth, Dan and Dorr, Bonnie J. and Gaasterland, Terry and Ng, Jun-Ping and Kan, Min-Yen and Xu, Feiyu and Uszkoreit, Hans and Li, Hong and Bethard, Steven and Martin, James H and Hoffart, Johannes and Fabian, M and Berberich, Klaus and Weikum, Gerhard and Hoffart, Johannes and Berberich, Klaus and Weikum, Gerhard and Suchanek, Fabian M F.M. Fm and Hoffart, Johannes and Kuzey, E. and Lewis-Kelham, E. and Mahdisoltani, Farzaneh and Biega, Joanna and Suchanek, Fabian M F.M. Fm and Rui, H E and Bing, Q I N and Ting, L I U and Yue, P A N and Sheng, L I and Ping, W U and Qun, Chen and Liang, M A},
booktitle = {Conference on Innovative Data Systems Research (CIDR)},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Demner-Fushman et al. - 2015 - YAGO3 A Knowledge Base from Multilingual Wikipedias.pdf:pdf},
title = {{YAGO3: A Knowledge Base from Multilingual Wikipedias}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Automatic+Event+and+Relation+Detection+with+Seeds+of+Varying+Complexity{\#}0{\%}5Cnhttp://www.aclweb.org/anthology/C12-1129{\%}5Cnhttp://dx.doi.org/10.1016/j.jbi.2013.08.010{\%}5Cnhttp://www.informatik.uni},
year = {2015}
}
@article{Kuo2010,
author = {Kuo, Yen-Ling and Hsu, Jane Yung-jen},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuo, Hsu - 2010 - Goal-Oriented Knowledge Collection.pdf:pdf},
isbn = {9781577354840},
journal = {AAAI Fall Symposium: Commonsense Knowledge},
keywords = {AAAI Technical Report FS-10-02},
pages = {64--69},
title = {{Goal-Oriented Knowledge Collection.}},
url = {http://www.aaai.org/ocs/index.php/FSS/FSS10/paper/viewPDFInterstitial/2278/2605},
year = {2010}
}
@book{DretskeFred;B.JackCopeland;AysePinarSaygin,
author = {{Dretske, Fred; B. Jack Copeland; Ayse Pinar Saygin}, Ilyas Cicekli; Varol Akman; SusaN g. sTERRETT; sAUL tRAIGER; gUALTIERO Piccinini; Sean Zdenek; Bruce Edmonds; Edmund M.A. Ronald; William J. Rapaport; Larry Hauser; James H. Moor; Selmer Bringsjord; Pau Bello; Dabvid Ferrucci; Gerald J. Erion; S. Hernad;},
edition = {1st},
editor = {{Moor, James H. (Dartmouth College, Hanover}, U.S.A.)},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dretske, Fred B. Jack Copeland Ayse Pinar Saygin - Unknown - The turing test, The Elusive Standard of Artificial Intelligence.pdf:pdf},
isbn = {9781402012051},
publisher = {Springer},
title = {{The turing test, The Elusive Standard of Artificial Intelligence}}
}
@inproceedings{Mitchell2015,
abstract = {Whereas people learn many different types of knowledge from diverse experiences over many years, most current ma- chine learning systems acquire just a single function or data model from just a single data set. We propose a never- ending learning paradigm for machine learning, to better re- flect the more ambitious and encompassing type of learn- ing performed by humans. As a case study, we describe the Never-Ending Language Learner (NELL), which achieves some of the desired properties of a never-ending learner, and we discuss lessons learned. NELL has been learning to read the web 24 hours/day since January 2010, and so far has ac- quired a knowledge base with over 80 million confidence- weighted beliefs (e.g., servedWith(tea, biscuits)). NELL has also learned millions of features and parameters that enable it to read these beliefs from the web. Additionally, it has learned to reason over these beliefs to infer new beliefs, and is able to extend its ontology by synthesizing new relational predi- cates. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL. Introduction},
author = {Mitchell, T and Cohen, W and Hruschka, E and Talukdar, P and Betteridge, J and Carlson, A and Dalvi, B and Gardner, M},
booktitle = {Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15)},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitchell et al. - 2015 - Never-Ending Learning.pdf:pdf},
title = {{Never-Ending Learning}},
year = {2015}
}
@article{Kang2005,
abstract = {Location-aware systems are proliferating on a variety of platforms from laptops to cell phones. Locations are expressed in two principal ways: coordinates and landmarks. However, users are often more interested in “places” rather than locations. A place is a locale that is important to an individual user and carries important semantic meanings such as being a place where one works, lives, plays, meets socially with others, etc. Our devices can make more intelligent decisions on how to behave when they have this higher level information. For example, a cell phone can switch to a silent mode when the user is in a quiet place (e.g., a movie theater, a lecture hall, or a place where one meets socially with others). It would be tedious to define this in terms of coordinates. In this paper, we describe an algorithm for extracting significant places from a trace of coordinates, and evaluate the algorithm with real data collected using Place Lab [14], a coordinate-based location system that uses a database of locations for WiFi hotspots.},
annote = {Is this one maybe an algorithm we call SPD?},
author = {Kang, Jong Hee and Welbourne, William and Stewart, Benjamin and Borriello, Gaetano},
doi = {10.1145/1094549.1094558},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kang et al. - 2005 - Extracting places from traces of locations(2).pdf:pdf},
isbn = {1581138776},
issn = {15591662},
journal = {ACM SIGMOBILE Mobile Computing and Communications Review},
number = {3},
pages = {58},
title = {{Extracting places from traces of locations}},
volume = {9},
year = {2005}
}
@article{VonAhn2006,
abstract = {Through online games, people can collectively solve large-scale computational problems. Such games constitute a general mechanism for using brain power to solve open problems. In fact, designing such a game is much like designing an algorithm - it must be proven correct, its efficiency can be analyzed, a more efficient version can supersede a less efficient one, and so on. "Games with a purpose" have a vast range of applications in areas as diverse as security, computer vision, Internet accessibility, adult content filtering, and Internet search. Any game designed to address these and other problems must ensure that game play results in a correct solution and, at the same time, is enjoyable. People will play such games to be entertained, not to solve a problem - no matter how laudable the objective},
author = {von Ahn, L.},
doi = {10.1109/MC.2006.196},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/von Ahn - 2006 - Games with a Purpose.pdf:pdf},
isbn = {0001-0782},
issn = {0018-9162},
journal = {Computer},
number = {6},
pages = {92--94},
pmid = {20192282},
title = {{Games with a Purpose}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1642623},
volume = {39},
year = {2006}
}
@article{Panton2002a,
abstract = {The KRAKEN toolset is a comprehensive interface for knowledge acquisition that operates in conjunction with the Cyc knowledge base. The KRAKEN system is designed to allow subject-matter experts to make meaningful additions to an existing knowledge base, without the benefit of training in the areas of artificial intelligence, ontology development, or logical representation. Users interact with KRAKEN via a natural-language interface, which translates back and forth between English and the KB's logical representation language. A variety of specialized tools are available to guide users through the process of creating new concepts, stating facts about those concepts, and querying the knowledge base. KRAKEN has undergone two independent performance evaluations. In this paper we describe the general structure and several of the features of KRAKEN, focussing on key aspects of its functionality in light of the specific knowledge-formation and acquisition challenges they are intended to address.},
author = {Panton, Kathy and Miraglia, Pierluigi and Salay, Nancy and Kahlert, Robert Christian and Baxter, David and Reagan, Roland},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Panton et al. - 2002 - Knowledge Formation and Dialogue Using the KRAKEN Toolset.pdf:pdf},
journal = {Proceedings of the Fourteenth National Conference on Innovative Applications of Artificial Intelligence},
pages = {900--905},
title = {{Knowledge Formation and Dialogue Using the KRAKEN Toolset}},
year = {2002}
}
@article{Bernstein2009,
abstract = {We present Collabio, a social tagging game within an online social network that encourages friends to tag one another. Collabio's approach of incentivizing members of the social network to generate information about each other produces personalizing information about its users. We report usage log analysis, survey data, and a rating exercise demonstrating that Collabio tags are accurate and augment information that could have been scraped online.},
author = {Bernstein, Michael and Tan, Desney and Smith, Greg and Czerwinski, Mary and Horvitz, Eric},
doi = {10.1145/1622176.1622195},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/Collabio - game.pdf:pdf},
isbn = {9781605587455},
issn = {00325910},
journal = {Proceedings of the 22nd annual ACM symposium on User interface software and technology (UIST '09)},
pages = {97--100},
title = {{Collabio: a game for annotating people within social networks}},
url = {http://dl.acm.org/citation.cfm?id=1622195},
year = {2009}
}
@article{Kuo2009,
abstract = {Games with A Purpose have successfully harvested information from web users. However, designing games that encourage sustainable and quality data contribution remains a great challenge. Given that many online communities have enjoyed active participation from a loyal following, this research explores how human computation games may benefit from rich interactions inherent in a community. We experimented by implementing two games for commonsense data collection on the leading social community platforms: the Rapport Game on Facebook and the Virtual Pet Game on PTT. In this paper, we present the choices of interaction mode and goal-oriented user model for building a community-based game. The data quality, collection efficiency, player retention, concept diversity, and game stability of both games are analyzed quantitatively from data collected since August/November 2008. Our findings should provide useful suggestions for designing community-based games in the future.},
author = {Kuo, Yen-ling and Lee, Jong-Chuan and Chiang, Kai-yang and Wang, Rex and Shen, Edward and Chan, Cheng-wei and Hsu, Jane Yung-jen},
doi = {10.1145/1600150.1600154},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuo et al. - 2009 - Community-Based Game Design Experiments on Social Games for Commonsense Data Collection.pdf:pdf},
isbn = {9781605586724},
issn = {978-1-60558-193-4},
journal = {Proceedings of the ACM SIGKDD Workshop on Human Computation (HCOMP)},
keywords = {games with a purpose,human computation,online community,social interaction},
pages = {15--22},
title = {{Community-Based Game Design: Experiments on Social Games for Commonsense Data Collection}},
url = {http://dl.acm.org/citation.cfm?id=1600150.1600154},
year = {2009}
}
@article{Fader2011,
abstract = {Open Information Extraction (IE) is the task of extracting assertions from massive corpora without requiring a pre-specified vocabulary. This paper shows that the output of state-of-the-art Open IE systems is rife with uninformative and incoherent extractions. To overcome these problems, we introduce two simple syntactic and lexical constraints on binary relations expressed by verbs. We implemented the constraints in the ReVerb Open IE system, which more than doubles the area under the precision-recall curve relative to previous extractors such as TextRunner and woepos. More than 30{\%} of ReVerb's extractions are at precision 0.8 or higher---compared to virtually none for earlier systems. The paper concludes with a detailed analysis of ReVerb's errors, suggesting directions for future work.},
archivePrefix = {arXiv},
arxivId = {arXiv:1411.4166v4},
author = {Fader, Anthony and Soderland, Stephen and Etzioni, Oren},
doi = {10.1234/12345678},
eprint = {arXiv:1411.4166v4},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/Identifying relations for open information extraction..pdf:pdf},
isbn = {978-1-937284-11-4},
issn = {1937284115},
journal = {Proceedings of the Conference on {\ldots}},
pages = {1535--1545},
pmid = {14199369},
title = {{Identifying relations for open information extraction}},
url = {http://dl.acm.org/citation.cfm?id=2145596{\%}5Cnhttp://dl.acm.org/citation.cfm?id=2145596{\%}5Cnhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.226.1089{\&}rep=rep1{\&}type=pdf{\%}5Cnhttp://www.cs.washington.edu/research/projects/aiweb/media/papers/etzioni-ijca},
year = {2011}
}
@article{Suchanek2008,
abstract = {This article presents YAGO, a large ontology with high coverage and precision. YAGO has been automatically derived from Wikipedia and WordNet. It comprises entities and relations, and currently contains more than 1.7 million entities and 15 million facts. These include the taxonomic Is-A hierarchy as well as semantic relations between entities. The facts for YAGO have been extracted from the category system and the infoboxes of Wikipedia and have been combined with taxonomic relations from WordNet. Type checking techniques help us keep YAGO's precision at 95{\%}-as proven by an extensive evaluation study. YAGO is based on a clean logical model with a decidable consistency. Furthermore, it allows representing n-ary relations in a natural way while maintaining compatibility with RDFS. A powerful query model facilitates access to YAGO's data. {\textcopyright} 2008.},
archivePrefix = {arXiv},
arxivId = {arXiv:1203.5073v1},
author = {Suchanek, Fabian M. and Kasneci, Gjergji and Weikum, Gerhard},
doi = {10.1016/j.websem.2008.06.001},
eprint = {arXiv:1203.5073v1},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Suchanek, Kasneci, Weikum - 2008 - YAGO A Large Ontology from Wikipedia and WordNet.pdf:pdf},
isbn = {1570-8268},
issn = {15708268},
journal = {Web Semantics},
keywords = {Information extraction,Knowledge representation,Ontologies},
number = {3},
pages = {203--217},
title = {{YAGO: A Large Ontology from Wikipedia and WordNet}},
volume = {6},
year = {2008}
}
@article{Matuszek2004,
author = {Matuszek, Cynthia and Witbrock, Michael and Kahlert, Robert C and Cabral, John and Schneider, Dave and Shah, Purvesh and Lenat, Douglas Bruce},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Matuszek et al. - 2004 - Searching for Common Sense Populating Cyc ™ from the Web.pdf:pdf},
journal = {Search},
title = {{Searching for Common Sense : Populating Cyc ™ from the Web}},
year = {2004}
}
@inproceedings{Witbrock2010,
address = {Cavtat/Dubrovnik},
annote = {Describes CURE},
author = {Witbrock, Michael},
booktitle = {Proceedings of the ITI 2010, 32nd International Conference on Information Technology Interfaces},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Witbrock - 2010 - Acquiring and Using Large Scale Knowledge Knowledge Capture Mixed Initiative.pdf:pdf},
pages = {37--42},
title = {{Acquiring and Using Large Scale Knowledge Knowledge Capture : Mixed Initiative}},
url = {http://ieeexplore.ieee.org/document/5546360/?reload=true{\&}tp={\&}arnumber=5546360},
year = {2010}
}
@techreport{Wallace2003,
author = {Wallace, Richard S.},
doi = {10.1.1.693.3664},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wallace - 2003 - The Elements of AIML Style.pdf:pdf},
institution = {Alice AI Foundation},
keywords = {AIML,Chatbot,Loebner},
mendeley-tags = {AIML,Chatbot,Loebner},
title = {{The Elements of AIML Style}},
url = {http://www.alicebot.org/style.pdf},
year = {2003}
}
@article{Masters2007,
author = {Masters, James and Matuszek, Cynthia and Witbrock, Michael},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/Knosis.pdf:pdf},
journal = {Cycorp},
keywords = {knowledge management,ontologies,web integration},
title = {{Ontology-Based Integration of Knowledge from Semi-Structured Web Pages}},
year = {2007}
}
@inproceedings{Sharma2010,
author = {Sharma, Abhishek and Forbus, Kenneth D},
booktitle = {2010 AAAI Fall Symposium Series},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharma, Forbus - 2010 - Graph-Based Reasoning and Reinforcement Learning for Improving QA Performance in Large Knowledge-Based Systems.pdf:pdf},
isbn = {9781577354840},
keywords = {AAAI Technical Report FS-10-02},
pages = {96--101},
title = {{Graph-Based Reasoning and Reinforcement Learning for Improving Q/A Performance in Large Knowledge-Based Systems}},
url = {http://www.aaai.org/ocs/index.php/FSS/FSS10/paper/download/2246/2596},
year = {2010}
}
@misc{TabooGame,
annote = {This is a board game which was inspiration for Verbosity.},
author = {Hasbro},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/fbb4512ece3e45956bcf23c977313d4dbea1ed87.pdf:pdf},
isbn = {1011433400},
title = {{Taboo board game}},
url = {https://www.hasbro.com/common/documents/dad288731c4311ddbd0b0800200c9a66/2BF862075056900B1021F6D7061EDCC7.pdf}
}
@inproceedings{Forbus2007,
address = {Vancouver,BC},
author = {Forbus, Kenneth D and Riesbeck, Christopher and Birnbaum, Lawrence and Livingston, Kevin and Sharma, Abhishek and Ureel, Leo},
booktitle = {Proceedings of AAAI-07: Twenty-Second Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Forbus et al. - 2007 - Integrating Natural Language , Knowledge Representation and Reasoning , and Analogical Processing to Learn by Rea.pdf:pdf},
title = {{Integrating Natural Language , Knowledge Representation and Reasoning , and Analogical Processing to Learn by Reading Learning Reader : The System}},
year = {2007}
}
@article{Lehmann2015,
abstract = {The DBpedia community project extracts structured, multilingual knowledge from Wikipedia and makes it freely available on theWeb using SemanticWeb and Linked Data technologies. The project extracts knowledge from 111 different language editions ofWikipedia. The largest DBpedia knowledge base which is extracted from the English edition ofWikipedia consists of over 400 million facts that describe 3.7 million things. The DBpedia knowledge bases that are extracted from the other 110Wikipedia editions together consist of 1.46 billion facts and describe 10 million additional things. The DBpedia project maps Wikipedia infoboxes from 27 different language editions to a single shared ontology consisting of 320 classes and 1,650 properties. The mappings are created via a world-wide crowd-sourcing effort and enable knowledge from the differentWikipedia editions to be combined. The project publishes releases of all DBpedia knowledge bases for download and provides SPARQL query access to 14 out of the 111 language editions via a global network of local DBpedia chapters. In addition to the regular releases, the project maintains a live knowledge base which is updated whenever a page inWikipedia changes. DBpedia sets 27 million RDF links pointing into over 30 external data sources and thus enables data from these sources to be used together with DBpedia data. Several hundred data sets on theWeb publish RDF links pointing to DBpedia themselves and make DBpedia one of the central interlinking hubs in the Linked Open Data (LOD) cloud. In this system report, we give an overview of the DBpedia community project, including its architecture, technical implementation, maintenance, internationalisation, usage statistics and applications.},
author = {Lehmann, Jens and Isele, Robert and Jakob, Max and Jentzsch, Anja and Kontokostas, Dimitris and Mendes, Pablo N. and Hellmann, Sebastian and Morsey, Mohamed and {Van Kleef}, Patrick and Auer, S{\"{o}}ren and Bizer, Christian},
doi = {10.3233/SW-140134},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/DBPedia2015.pdf:pdf},
isbn = {1570-0844},
issn = {22104968},
journal = {Semantic Web},
keywords = {Knowledge extraction,Linked Data,RDF,Wikipedia,multilingual knowledge bases},
number = {2},
pages = {167--195},
title = {{DBpedia - A large-scale, multilingual knowledge base extracted from Wikipedia}},
volume = {6},
year = {2015}
}
@article{Coursey2004,
author = {Coursey, Kino},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Coursey - 2004 - LIVING IN CYN MATING AIML AND CYC TOGETHER WITH PROGRAM N.pdf:pdf},
title = {{LIVING IN CYN : MATING AIML AND CYC TOGETHER WITH PROGRAM N}},
year = {2004}
}
@article{Downey2005,
abstract = {Unsupervised Information Extraction (UIE) is the task of extracting knowledge from text without using hand-tagged training examples. A fundamental problem for both UIE and supervised IE is assessing the probability that extracted information is correct. In massive corpora such as the Web, the same extraction is found repeatedly in different documents. How does this redundancy impact the probability of correctness? This paper introduces a combinatorial "balls-andurns" model that computes the impact of sample size, redundancy, and corroboration from multiple distinct extraction rules on the probability that an extraction is correct. We describe methods for estimating the model's parameters in practice and demonstrate experimentally that for UIE the model's log likelihoods are 15 times better, on average, than those obtained by Pointwise Mutual Information (PMI) and the noisy-or model used in previous work. For supervised IE, the model's performance is comparable to that of Support Vector Machines, and Logistic Regression.},
author = {Downey, Doug and Etzioni, Oren and Soderland, Stephen},
doi = {10.1016/j.artint.2010.04.024},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Downey, Etzioni, Soderland - 2005 - A probabilistic model of redundancy in information extraction.pdf:pdf},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {1034--1041},
title = {{A probabilistic model of redundancy in information extraction}},
year = {2005}
}
@article{McKinstry2008,
abstract = {When deciding between two alternatives, such as whether to order the pasta or the chicken, or whether to pursue a career in academia or industry, a person may feel torn—as if the options literally pull him or her in two directions. This metaphor may have some surprising literal truth. If asked, for example, whether ‘‘murder is sometimes justified,'' individuals may be inclined to both agree and disagree with the statement. Here, we document, for the first time, the pull toward contrasting responses during evaluative thinking, reporting the results of a study examining the trajectory of participants' reaching movements toward dif- ferent response options. Our results suggest that a decision process is not necessarily completed in the brain's cognitive subsystems before it is shared with other subsystems, as has been traditionally assumed. Rather, simultaneous ‘‘pull'' from multiple response alternatives seems to influence the execution of movement itself. This finding suggests that a dynamic approach to mental processing—an approach that has already provided descriptions of perception, attention, and categorization (e.g., Abrams{\&}Balota, 1991; Gold {\&}Shadlen, 2000; Gratton, Coles, Sirevaag, Eriksen,{\&}Donchin, 1988; Hovland {\&} Sears, 1938; McClelland {\&} Rogers, 2003; Spivey, 2007; Tipper, Howard, {\&} Houghton, 1999)—may shed new light on high-level cognition (Roe, Busemeyer, {\&} Town- send, 2001; Townsend {\&} Busemeyer, 1989).},
author = {McKinstry, Chris and Dale, Rick and Spivey, Michael J.},
doi = {10.1111/j.1467-9280.2008.02041.x},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McKinstry, Dale, Spivey - 2008 - Action dynamics reveal parallel competition in decision making.pdf:pdf},
isbn = {1467-9280},
issn = {09567976},
journal = {Psychological Science},
number = {1},
pages = {22--24},
pmid = {18181787},
title = {{Action dynamics reveal parallel competition in decision making}},
volume = {19},
year = {2008}
}
@article{Witbrock2005,
author = {Witbrock, Michael and Matuszek, Cynthia and Brusseau, Antoine and Kahlert, Robert C and Fraser, C Bruce and Lenat, Douglas B.},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Witbrock et al. - 2005 - Knowledge Begets Knowledge Steps towards Assisted Knowledge Acquisition in Cyc.pdf:pdf},
journal = {AAAI Spring Symposium: Knowledge Collection from Volunteer Contributors},
keywords = {American Association,Compilation copyright {\textcopyright} 2005},
pages = {99--105},
title = {{Knowledge Begets Knowledge: Steps towards Assisted Knowledge Acquisition in Cyc}},
url = {http://www.aaai.org/Papers/Symposia/Spring/2005/SS-05-03/SS05-03-015.pdf},
year = {2005}
}
@misc{Mueller2003,
abstract = {This paper provides an overview of ThoughtTreasure, a comprehensive platform for natural language processing and commonsense reasoning. ThoughtTreasure contains on the order of 100,000 pieces of common sense associated with 55,000 English and French words and phrases. We describe the ThoughtTreasure commonsense knowledge base and architecture for natural language processing. We then discuss how commonsense knowledge is represented in ThoughtTreasure using multiple schemes including logic, finite automata, and grids. We then present applications of ThoughtTreasure, including story understanding by building and maintaining a simulation of the states and events described in a story.},
author = {Mueller, Erik T},
title = {{ThoughtTreasure: A natural language/commonsense platform}},
url = {http://alumni.media.mit.edu/{~}mueller/papers/tt.html},
urldate = {2017-01-01},
year = {2003}
}
@article{Etzioni2011,
author = {Etzioni, Oren and Fader, Anthony and Christensen, Janara and Soderland, Stephen and Mausam, Mausam},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Etzioni et al. - 2011 - Open Information Extraction The Second Generation.pdf:pdf},
journal = {Proc. Int. Joint Conf. Artificial Intell.},
title = {{Open Information Extraction: The Second Generation.}},
year = {2011}
}
@article{Soderland2007,
abstract = {Traditionally, Information Extraction (IE) has focused on satisfying precise, narrow, pre-specified requests from small homogeneous corpora (e.g., extract the location and time of seminars from a set of announcements). Shifting to a new domain requires the user to name the target relations and to manually create new extraction rules or hand-tag new training examples. This manual labor scales linearly with the number of target relations. This paper introduces Open IE (OIE), a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiring any human input. The paper also introduces TEXTRUNNER, a fully implemented, highly scalable OIE system where the tuples are assigned a probability and indexed to support efficient extraction and exploration via user queries. We report on experiments over a 9,000,000 Web page corpus that compare TEXTRUNNER with KNOWITALL, a state-of-the-art Web IE system. TEXTRUNNER achieves an error reduction of 33{\%} on a comparable set of extractions. Furthermore, in the amount of time it takes KNOWITALL to perform extraction for a handful of pre-specified relations, TEXTRUNNER extracts a far broader set of facts reflecting orders of magnitude more relations, discovered on the fly. We report statistics on TEXTRUNNER's 11,000,000 highest probability tuples, and show that they contain over 1,000,000 concrete facts and over 6,500,000 more abstract assertions.},
author = {Soderland, Stephen and Broadhead, Matt and Banko, Michele and Cafarella, Michael J. and Etzioni, Oren},
doi = {10.1145/1409360.1409378},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Soderland et al. - 2007 - Open information extraction from the web.pdf:pdf},
isbn = {1581138741},
issn = {00010782},
journal = {International Joint Conference On Artificial Intelligence},
pages = {2670--2676},
pmid = {25810777},
title = {{Open information extraction from the web}},
url = {http://portal.acm.org/citation.cfm?id=1625705},
year = {2007}
}
@inproceedings{Pedro2013,
author = {Pedro, S D S and Appel, A P and Jr, E R Hruschka},
booktitle = {Proceedings of the 22nd {\ldots}},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pedro, Appel, Jr - 2013 - Autonomously reviewing and validating the knowledge base of a never-ending learning system.pdf:pdf},
isbn = {9781450320382},
keywords = {active learning,anomaly link detection,graph mining,never-ending-learning,question answering},
pages = {1195--1203},
title = {{Autonomously reviewing and validating the knowledge base of a never-ending learning system}},
url = {http://dl.acm.org/citation.cfm?id=2488149},
year = {2013}
}
@inproceedings{Feigenbaum1977,
author = {Feigenbaum, E. A.},
booktitle = {Proceedings of the 5th International Joint Conference of Artificial itelligence},
pages = {1014--1029},
title = {{The Art of Artificial Intelligence: Themses and Case Studies of Knowledge Engineering}},
year = {1977}
}
@article{Dong2010,
abstract = {It is widely acknowledged that natural language processing, as an indispensable means for information technology, requires the strong support of world knowledge as well as linguistic knowledge. This book is a theoretical exploration into the extra-linguistic knowledge needed for natural language processing and a panoramic description of HowNet as a case study. Readers will appreciate the uniqueness of the discussion on the definitions of the top-level classes HowNet specifies, such as things, parts, attributes, time, space, events and attribute-values, and the relations among them, and also the depth of the authors' philosophy behind HowNet. The book describes the attraction of HowNet's computability of meanings and how a software of meaning computation can collect so many relevant words and expressions of `the', or give a similarity value between any two words or expressions.},
author = {Dong, Zhendong and Dong, Qiang and Hao, Changling},
doi = {10.1142/9789812774675},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong, Dong, Hao - 2010 - HowNet and Its Computation of Meaning.pdf:pdf},
isbn = {9789812564917},
journal = {Coling 2010},
number = {August},
pages = {53--56},
title = {{HowNet and Its Computation of Meaning}},
year = {2010}
}
@inproceedings{Speer2008,
abstract = {We are interested in the problem of reasoning over very large common sense knowledge bases. When such a knowledge base contains noisy and subjective data, it is important to have a method for making rough conclusions based on simi- larities and tendencies, rather than absolute truth. We present AnalogySpace, which accomplishes this by forming the ana- logical closure of a semantic network through dimensionality reduction. It self-organizes concepts around dimensions that can be seen as making distinctions such as “good vs. bad” or “easy vs. hard”, and generalizes its knowledge by judging where concepts lie along these dimensions. An evaluation demonstrates that users often agree with the predicted knowl- edge, and that its accuracy is an improvement over previous techniques. Introduction},
author = {Speer, Robert and Lieberman, Henry and Havasi, Catherine},
booktitle = {AAAI'08 Proceedings of the 23rd national conference on Artificial intelligence},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Speer, Lieberman, Havasi - 2008 - AnalogySpace Reducing the Dimensionality of Common Sense Knowledge.pdf:pdf},
isbn = {9781577353683},
keywords = {Knowledge Representation,Logic,and Information S},
pages = {548--553},
title = {{AnalogySpace : Reducing the Dimensionality of Common Sense Knowledge}},
year = {2008}
}
@article{Bernstein2010,
abstract = {When information is known only to friends in a social network, traditional crowdsourcing mechanisms struggle to motivate a large enough user population and to ensure accuracy of the collected information. We thus introduce friendsourcing, a form of crowdsourcing aimed at collecting accurate information available only to a small, socially-connected group of individuals. Our approach to friendsourcing is to design socially enjoyable interactions that produce the desired information as a side effect. We focus our analysis around Collabio, a novel social tagging game that we developed to encourage friends to tag one another within an online social network. Collabio encourages friends, family, and colleagues to generate useful information about each other. We describe the design space of incentives in social tagging games and evaluate our choices by a combination of usage log analysis and survey data. Data acquired via Collabio is typically accurate and augments tags that could have been found on Facebook or the Web. To complete the arc from data collection to application, we produce a trio of prototype applications to demonstrate how Collabio tags could be utilized: an aggregate tag cloud visualization, a personalized RSS feed, and a question and answer system. The social data powering these applications enables them to address needs previously difficult to support, such as question answering for topics comprehensible only to a few of a user's friends.},
author = {Bernstein, Michael and Tan, Desney and Smith, Greg and Czerwinski, Mary and Horvitz, Eric},
doi = {10.1145/1746259.1746260},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/Collabio - Pers.pdf:pdf},
isbn = {1073-0516},
issn = {10730516},
journal = {ACM Transactions on Computer-Human Interaction},
keywords = {Social computing,friendsourcing,human computation,social tagging},
number = {2},
pages = {1--28},
title = {{Personalization via friendsourcing}},
volume = {17},
year = {2010}
}
@article{Schubert2003,
abstract = {We have been developing techniques for extracting general world knowledge from miscellaneous texts by a process of approximate interpretation and abstraction, focusing initially on the Brown corpus. We apply interpretive rules to clausal patterns and patterns of modification, and concurrently abstract general "possibilistic" propositions from the resulting formulas. Two examples are "A person may believe a proposition", and "Children may live with relatives". Our methods currently yield over 117,000 such propositions (of variable quality) for the Brown corpus (more than 2 per sentence). We report here on our efforts to evaluate these results with a judging scheme aimed at determining how many of these propositions pass muster as "reasonable general claims" about the world in the opinion of human judges. We find that nearly 60{\%} of the extracted propositions are favorably judged according to our scheme by any given judge. The percentage unanimously judged to be reasonable claims by multiple judges is lower, but still sufficiently high to suggest that our techniques may be of some use in tackling the long-standing "knowledge acquisition bottleneck" in AI.},
author = {Schubert, Lenhart and Tong, Matthew},
doi = {10.3115/1119239.1119241},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schubert, Tong - 2003 - Extracting and evaluating general world knowledge from the Brown corpus.pdf:pdf},
journal = {Proceedings of the HLT-NAACL 2003 workshop on Text meaning - Volume 9},
keywords = {common{\_}sense},
pages = {7--13},
title = {{Extracting and evaluating general world knowledge from the Brown corpus}},
url = {http://dx.doi.org/10.3115/1119239.1119241},
year = {2003}
}
@inproceedings{Pedro2012a,
abstract = {The recent growth of virtual communities, social web and information sharing gives to information retrieval and ma- chine learning systems a source of information referred as the "wisdom of crowds". In this work we show that this infor- mation could be used not only as a source of knowledge but as a way to bring intelligent systems closer to users by using their opinion as part of the knowledge acquisition/validation allowing self-supervision. For that we have implemented a validation system for the NELL (Never-Ending Language Learner) system using the question answering platform given by the Yahoo!Answers web community. Moreover, we focus in this paper, in the validation of rst order rules induced by NELL using its Rule Learning (RL) algorithm. This pa- per presents the main motivations for using a QA forum in- stead of other web-based validation sources; describes the proposed approach with a $\backslash$Macro QA"-based component named SS-Crowd (self-supervisor agent based on the wisdom of crowds) and brings and discusses the obtained results and how they can impact in a never-ending learning system like NELL in which self-supervision plays a crucial role.},
author = {Pedro, Saulo D. S. and Hruschka, Estevam R.},
booktitle = {Proceedings of the 4th International Workshop on Web Intelligence {\&} Communities - WI{\&}C '12},
doi = {10.1145/2189736.2189744},
file = {:D$\backslash$:/Data/Dropbox/Delo/Desktop/ka/2012 - Pedro, Collective Intelligence as a Source for Machine Learning Self-Supervision.pdf:pdf},
isbn = {9781450311892},
keywords = {knowledge validation,machine learning,question answering,self-supervision},
number = {3},
pages = {1},
title = {{Collective intelligence as a source for machine learning self-supervision}},
url = {http://dl.acm.org/citation.cfm?id=2189736.2189744},
year = {2012}
}
