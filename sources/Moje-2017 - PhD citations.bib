Automatically generated by Mendeley Desktop 1.17.9
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Sharma2010,
author = {Sharma, Abhishek and Forbus, KD},
booktitle = {2010 AAAI Fall Symposium Series},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharma, Forbus - 2010 - Graph-Based Reasoning and Reinforcement Learning for Improving QA Performance in Large Knowledge-Based Systems.pdf:pdf},
isbn = {9781577354840},
keywords = {AAAI Technical Report FS-10-02},
pages = {96--101},
title = {{Graph-Based Reasoning and Reinforcement Learning for Improving Q/A Performance in Large Knowledge-Based Systems}},
url = {http://www.aaai.org/ocs/index.php/FSS/FSS10/paper/download/2246/2596},
year = {2010}
}
@article{Zang2013,
abstract = {Collecting massive commonsense knowledge (CSK) for commonsense reasoning has been a long time standing challenge within artificial intelligence research. Numerous methods and systems for acquiring CSK have been developed to overcome the knowledge acquisition bottleneck. Although some specific commonsense reasoning tasks have been presented to allow researchers to measure and compare the performance of their CSK systems, we compare them at a higher level from the following aspects: CSK acquisition task (what CSK is acquired from where), technique used (how can CSK be acquired), and CSK evaluation methods (how to evaluate the acquired CSK). In this survey, we first present a categorization of CSK acquisition systems and the great challenges in the field. Then, we review and compare the CSK acquisition systems in detail. Finally, we conclude the current progress in this field and explore some promising future research issues.},
annote = {Good survey for related work. Main conclusions:

- Mostly measuring correctness of the kwnowledge and efficiency of collecting. Missing good evaluation methiods.
- Kako usefulness?


related work:
[46] = rewards user when he answers (Prebral)
[19] = answers in NL (Prebral)
[21] = automatically transform NL into the formal representation
[22,26,27] = Infer new knowledge after get some knowledge - !!my idea-need to check
[30] Interactive KA approach
[33,34] = Open Information Extraction - To inspire further work !!important to check!!
[37,38,54] = CYC for Q/A already!
[18] = Naucil so se lessions while hand coding Cyc
[58]Kraken, [59] UIIA, [27] Predicate Populator = CC Competitors
[37]= Cyc KA using pre-existing knowledge !!!My idea as well
[60] = generate rules automatically
[10] = Commercial Cyc based QA

[66] = SmartCalendar, ThoughtTreasure app
!!![67,28, 82] Verbosity game to fill OMCS knowledge
[30] 20 questions game - Janez's idea as side CC thing

[76] ConceptNet-3 says it does NL to logic, logic to NL - what CC needs
[72, 82] = Games with a Purpose
[32] - ideal, complete CSKB
[31] - Virtual pet game

[48, 23] Evaluation, some comparison to Cyc
[38] Learning by reading -Cyc stuff as well
[21] - Knowledge Gap problem
[30] - guide users to enter the missing knowledge

[32] Liner Regression to measure new knowledge each day},
author = {Zang, Liang-Jun and Cao, Cong and Cao, Ya-Nan and Wu, Yu-Ming and CAO, Cun-Gen},
doi = {10.1007/s11390-013-1369-6},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zang et al. - 2013 - A Survey of Commonsense Knowledge Acquisition.pdf:pdf},
issn = {1000-9000},
journal = {Journal of Computer Science and Technology},
keywords = {KA,Survey,commonsense knowledge,knowledge acquisition,knowledge representation and reasoning},
mendeley-tags = {KA,Survey},
month = {jul},
number = {4},
pages = {689--719},
title = {{A Survey of Commonsense Knowledge Acquisition}},
url = {http://link.springer.com/10.1007/s11390-013-1369-6},
volume = {28},
year = {2013}
}
@article{Mitchell2015,
abstract = {Whereas people learn many different types of knowledge from diverse experiences over many years, most current ma- chine learning systems acquire just a single function or data model from just a single data set. We propose a never- ending learning paradigm for machine learning, to better re- flect the more ambitious and encompassing type of learn- ing performed by humans. As a case study, we describe the Never-Ending Language Learner (NELL), which achieves some of the desired properties of a never-ending learner, and we discuss lessons learned. NELL has been learning to read the web 24 hours/day since January 2010, and so far has ac- quired a knowledge base with over 80 million confidence- weighted beliefs (e.g., servedWith(tea, biscuits)). NELL has also learned millions of features and parameters that enable it to read these beliefs from the web. Additionally, it has learned to reason over these beliefs to infer new beliefs, and is able to extend its ontology by synthesizing new relational predi- cates. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL. Introduction},
author = {Mitchell, T and Cohen, W and Hruschka, E and Talukdar, P and Betteridge, J and Carlson, A and Dalvi, B and Gardner, M},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitchell et al. - 2015 - Never-Ending Learning.pdf:pdf},
journal = {Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15)},
title = {{Never-Ending Learning}},
year = {2015}
}
@inproceedings{Furbus2007,
address = {Vancouver,BC},
author = {Forbus, Kenneth D and Riesbeck, Christopher and Birnbaum, Lawrence and Livingston, Kevin and Sharma, Abhishek and Ureel, Leo},
booktitle = {Proceedings of AAAI-07: Twenty-Second Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Forbus et al. - 2007 - Integrating Natural Language , Knowledge Representation and Reasoning , and Analogical Processing to Learn by Rea.pdf:pdf},
title = {{Integrating Natural Language , Knowledge Representation and Reasoning , and Analogical Processing to Learn by Reading Learning Reader : The System}},
year = {2007}
}
@article{Kuo2010,
author = {Kuo, YL and Hsu, JY},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuo, Hsu - 2010 - Goal-Oriented Knowledge Collection.pdf:pdf},
isbn = {9781577354840},
journal = {AAAI Fall Symposium: Commonsense Knowledge},
keywords = {AAAI Technical Report FS-10-02},
pages = {64--69},
title = {{Goal-Oriented Knowledge Collection.}},
url = {http://www.aaai.org/ocs/index.php/FSS/FSS10/paper/viewPDFInterstitial/2278/2605},
year = {2010}
}
@inproceedings{Witbrock2003,
address = {Acapulco, Mexico},
author = {Witbrock, Michael and Baxter, David and Curtis, Jon and Schneider, Dave and Kahlert, Robert Christian and Miraglia, Pierluigi and Wagner, Peter and Panton, Kathy and Matthews, Gavin and Vizedom, Amanda},
booktitle = {Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Witbrock et al. - 2003 - An Interactive Dialogue System for Knowledge Acquisition in Cyc.pdf:pdf},
title = {{An Interactive Dialogue System for Knowledge Acquisition in Cyc}},
year = {2003}
}
@article{Singh2002a,
abstract = {Abstract. Open Mind Common Sense is a knowledge acquisition system de- signed to acquire commonsense knowledge from the general public over the web. We describe and evaluate our first fielded system, which enabled the construction of a 450,000 assertion commonsense knowledge base. We then discuss how our second-generation system addresses weaknesses discovered in the first. The new system acquires facts, descriptions, and stories by allowing participants to construct and fill in natural language templates. It employs word-sense disambiguation and methods of clarifying entered knowledge, ana- logical inference to provide feedback, and allows participants to validate knowledge and in turn each other.},
annote = {Prebral Februarja 2016

Tle so probal ze s
- templati,
- feedbackom z reasoningom
- slab rule acquisition


Here they evaluate the previous article. 

OMCS1 v 2h letih. September 2000- Avgust 2002, so dobili 456.195 pieces of knowledge from 9296 people

Manual evaluation:
3245 unique items (1{\%} cele).
236 (7.3{\%}) discarded - needed other material
7 judges:
370 (12.3{\%}) = garbage
ostalo rated od 1 do 5


[8](2001) intergrated KA system 
[9] Constrained NL KA (pulldowns)
[10] subset of english which is restricted enough to be converted into the 1st order.
[11] Reasoning
[21] = methods for acquiring procedural knowledge
[22] scripts for coordinating changes in the db
[23] reflective architectures},
author = {Singh, Push and Lin, Thomas and Mueller, E.T. and Lim, G. and Perkins, T. and Zhu, W.L.},
doi = {10.1007/3-540-36124-3_77},
file = {:C$\backslash$:/Users/lbradesko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh et al. - 2002 - Open Mind Common Sense Knowledge acquisition from the general public.pdf:pdf},
isbn = {3540001069},
issn = {03029743},
journal = {Cooperative Information Systems Oct. 30-Nov. 1 2002},
keywords = {KA,Open mind},
mendeley-tags = {KA,Open mind},
pages = {1223--1237},
title = {{Open Mind Common Sense: Knowledge acquisition from the general public}},
url = {http://portal.acm.org/citation.cfm?id=646748.701499},
year = {2002}
}
