%-------------------------------------------------------------------------------
%
\chapter{Background and Problem Definition}
\label{chapter:background}
%-------------------------------------------------------------------------------
This chapter describes the challenges and components that a Knowledge
Acquisition system such as the one presented in this work (\emph{Curious Cat})
has to address and 
bring together into an interconnected work-flow in order to be a coherent 
KA system able to satisfy the goals of general Knowledge Acquisition. 

\emph{Curious Cat} is a KA system making use of existing knowledge, 
logical inference, crowd-sourcing and mobile context, to trigger natural language
questions at user-appropriate moments and then incorporate the answers consistently
into the existing KB. To successfully do this, there are many inter connected
steps addressing a broad range of as yet not completely solved problems from
multiple fields of artificial intelligence, machine learning, natural language
processing and human computer interaction. Additionally to that, given
that the approach uses crowd-sourcing, there is additional complexity
of technical implementation and scalability issues. 

For a more structured explanation of the approach and challenges involved, this
section is grouped into sub-sections describing the main challenges.

The proposed approach that we have implemented in \emph{Curious Cat} is
knowledge driven, meaning that knowledge is connecting
all of the components, including the user interaction, and storing of the
results into the KB (Section \ref{section:bg:knowledge}). Its user context is 
obtained through a mobile sensor mining in a real-world application that 
monitors the userâ€™s activity and location through mobile GPS and accelerometer 
sensors. This raw data is then processed, clustered, classified and enriched 
before it is inserted into the KB (Section \ref{section:bg:context}).
The newly asserted context can trigger forward chaining operation of the 
inference engine (Section \ref{section:bg:knowledge}) which can result in a
logical representation of a new question (Section \ref{section:bg:ka}) or a 
statement that the system intends to show to the user. The aforementioned  
logical formula is then converted to natural language (Section 
\ref{section:bg:nlp}) and presented to the user through a mobile application. 
When the user answers, his natural language (NL) answer is converted to logic 
(Section \ref{section:bg:nlp}), checked by the inference engine against the 
existing knowledge for consistency, and inserted as a new piece of knowledge into 
the KB (Section \ref{section:bg:ka}). Then, the system determines whether to
continue the conversational path with the user or not. Newly acquired knowledge 
is then checked with other users for
validity (Section \ref{section:bg:crowdsourcing}) and is then used by the 
inference to produce new questions/comments/suggestions (Section 
\ref{section:bg:ka}).

\section{Knowledge Representation, Engineering and Inference}
\label{section:bg:knowledge}
The proposed Knowledge Acquisition (KA) approach described in 
Chapter \ref{chapter:approach} is completely knowledge driven. One of the main 
building blocks of our system is its knowledge base, which must be based on a 
representation language expressive enough to support the knowledge structures 
required to drive the behavior of the system, and to represent the wide variety 
of knowledge it may gather from the users. Additionally, the inference engine 
needs to be able to access knowledge from the KB and needs to be powerful enough 
to perform inference over it.

%subsection
\subsection{Knowledge Base}
\label{section:bg:kb}
The Knowledge Base (KB) is a crucial part of our KA approach 
(marked in purple in \autoref{fig:Architecture}). It dictates the expressiveness 
of the knowledge representation that we must use, as well as 
(together with the inference engine) the overall speed of the KA system. 
Although our approach is generally KB independent, each KB has its own 
specific characteristics, which need to be taken into consideration when 
representing and storing the acquired knowledge. As a part of this research we 
have considered three knowledge bases and the appropriateness of their 
knowledge representations.

\begin{enumerate}
\item The main system reported here was built based on the Cyc KB
\parencite{Lenat1995}, in a form similar to Research Cyc. 
\item Inspired by the Open Cyc representation we also developed our own 
knowledge base and inference engine, Umko, designed to be as simple as possible
while still supporting several of the typical use-cases presented here. 
Because of its simplicity, the approach built around Umko can run in totality 
on a 2015-quality smart phone.
\item Additionally, to test the generality of the approach, we used a similar 
idea with a standard RDF knowledge representation \parencite{Bradesko2012}.
\end{enumerate}

Requirements and specifics of the KB are described in more detail in 
Section \ref{section:kb} and also in the implementation Subsection \ref{section:cyckb}.

%subsection Inference engine
\subsection{Inference Engine}
\label{section:bg:inference}
In addition to the KB, the second most crucial part of the proposed system is an 
inference engine (marked in red in \autoref{fig:Architecture}) that can reason 
over the knowledge stored in the KB. The inference engine is used to detect 
the missing knowledge and infer what to ask and when, based on the context 
that is asserted as a part of the knowledge. Similarly to the knowledge base, 
the inference engine influences the speed and complexity of the approach. Our 
approach was again twofold. The main experiments were based on the Cyc 
inference engine (see Subsection \ref{section:cycinference}) which is tightly linked 
to the Cyc KB and thus able to apply inference over the biggest existing 
common sense KB. Additionally, we developed the inference capabilities 
(forward and backward chaining) inside our custom developed inference 
engine - Umko, needed to test the generalize-ability of the proposed approach 
and to make it possible to run on embedded devices.

%subsection
\subsection{Knowledge Representation}
\label{section:bg:representation}
The problem of representing knowledge in a computer is as old as the field of 
the AI research and has been tackled from various perspectives, but still not 
completely solved. The proposed approach relies on the Knowledge Representation
(KR) which is powerful 
enough to describe the real world we live in. Additionally, it needs to cover 
knowledge about the knowledge itself (meta-knowledge), enabling inference over 
internal knowledge structures, questions and answers (see Subsection \ref{section:kakb}
for approach and Subsection \ref{section:cyckb} for the implementation). 
This inference is used to 
produce statements and questions and interactions between them as part of a 
dialogue used to communicate with the user in the process of knowledge 
acquisition. We have tested two approaches, where one was fully based on 
the Cyc KB, and the other based on Umko, where we only created the 
minimal upper ontology and vocabulary to support the KA task. 

\section{Context (Information) Extraction}
\label{section:bg:context}
To be able to ask relevant questions, connected to the user or something that 
the user is currently doing or knows, and to ask at the right time/place, 
maintaining and using the user context is crucial. Using context and the newly 
acquired knowledge to drive the KA process, is one of the main contributions 
of this paper. 

Nowadays, the obvious information source to get to know the user is his or her
mobile phone, which, with its sensors, can provide an extensive and valuable 
source of information. However, the users need to approve access to their
phones sensors, and additionally, the raw measurements of sensor data need to
be processed and understood to the extent that it is possible to use that 
information in some sort of knowledge representation. In our approach, we used 
two types of the context. One was provided by the users directly via answering 
questions about themselves (Subsection \ref{section:bg:contextu} below and 
Subsection \ref{section:acquiredContext}). Another part 
of the context was mined from the phone sensors as introduced in 
Subsection \ref{section:bg:contextm} and described in Sections 
\ref{section:minedContext} and \ref{section:locationServlet}.

%subsection
\subsection{Mobile Sensor Stream Analytics (Mined Context)} 
\label{section:bg:contextu}
Mining raw sensor measurements and extracting the meaning out of the data is a 
sub-problem on its own. The proposed KA approach relies on mining mobile phone 
GPS coordinates and accelerometer sensors to extract the places where the user 
stays for a while, time of the visit, duration of the stay, and the path taken
to come there. Additionally, we are enriching these stay points with the name
and the type of location. This was done by applying a two pass stay point detect
(SPD) algorithm (see related work Subsection \ref{section:SPD1} and the Foursquare API. 
This is described in more detail in Sections \ref{section:minedContext} and
\ref{section:locationServlet}. Additionally, we use accelerometer sensors, 
to detect user activity (walking, running, cycling, driving, still), which is 
provided by Google as a part of the standard Android API. The resulting 
information extracted from the sensors is asserted into the KB as part of its 
contextual knowledge. This is depicted as an orange arrow in 
\autoref{fig:Architecture}.

\subsection{Knowledge Acquired from the User}
\label{section:bg:contextm}
In addition to the context that can be mined automatically from the mobile 
sensors, the KA process benefits substantially if it has additional information
about the user. For instance, what language she/he speaks, what are his/her 
interests, profession, food he/she likes, etc. This knowledge can be used by 
the KA rules to fine tune the questions and suggestions in order to generate 
more questions that the user can answer. Using context knowledge can make 
the questions more interesting for the user (e.g., asking the user if an 
already stored wireless password is still valid for a particular location that 
the user is currently at). In addition to specific hand crafted questions 
targeted at users' personal information, context acquisition can use gained 
knowledge to ask even more questions. Wherever there is some part of knowledge 
in the KB that can be connected to the person, the system constructs a 
personal question for each user. Refer to Subsection \ref{section:acquiredContext} for
the approach explanation.

\section{Knowledge Acquisition}
\label{section:bg:ka}
The main scientific contribution of this paper is a new approach to tackling 
the knowledge acquisition problem. The proposed approach combines natural 
language crowdsourcing, usage of prior knowledge, context and newly acquired 
knowledge. For this, we had to address many sub-problems of knowledge-driven 
KA as described in this section. The KA logic is all encoded as meta-knowledge 
in the KB and driven by inference. This is represented in red (B) and purple 
(A) in the architectural diagram in \autoref{fig:Architecture}.

\subsection{Question and Statement Formulation Logic} 
To be able to generate questions and other statements from a KB using an 
inference engine, there must first be a logic vocabulary supporting that 
construction. This means that the KB needs to have a meta-structure 
(knowledge representation) which allows it to describe its own contents and be
able to address assertions and other logical formulas and variables. After this
is in place, the approach needs logical rules that are used by the inference
engine to produce new logical queries or statements. As part of this research, 
we extended the existing Cyc vocabulary with supporting meta-structures and 
knowledge acquisition rules. This logic is described in Subsection \ref{section:kakb} and Subsection \ref{section:dialog}.

\subsection{Answer Consistency and KB Placement}
The logical queries and statements generated by the inference engine are 
converted to natural language (Section \ref{section:consistency}) and presented to the user. The user's answer is converted to logic (Subsection \ref{section:NLLogic}). 
Then the system checks whether the answer is coherent and consistent with the 
existing KB. This is crucial to avoid corrupting the KB over time as more new 
knowledge is added through the KA process. This check is performed with the 
help of the inference engine, which is triggered at the time of assertion of 
new knowledge and detects inconsistencies when or before an attempt to 
assert the answer into the KB is made. This process needs to be supported by a 
suitable knowledge representation, providing a suitable logical vocabulary. 
Our implementation addressing this problem is described in detail in 
Subsection \ref{section:cycnl}.

\subsection{Maximizing Knowledge Gain} 
As we are generating questions and incorporating the answers into the KB, it 
is obvious that some questions are more worthy of being asked than others. 
This details depend on the specific task of the knowledge acquisition, but 
regardless the task, some questions and answers are more valuable than the 
other. While this problem was not the main focus of this work, we addressed it 
partially by introducing vocabulary that allows us to control the order and 
priority of the questions, and also a mechanism to always show interesting
and user connected questions as described in \autoref{section:mainServlet}.

\subsection{Maximizing the chance of getting an answer}
Finding the right timing, location and other context to present the question
to the user. In the KA process, we want to maximize knowledge gain. A part of 
that is maximizing the chance of getting any answer from the user. The KA 
process thus become a multi-objective optimization, where we need to optimize 
multiple parameters to obtain as many answers as possible, while maintaining 
quality of the answers and keeping the user engaged at the right level (not 
bored and not overwhelmed). This is where the context helps the most as we can 
ask questions which are related to the users current situation. In particular, 
the user location, user activity and time of the day helps the inference 
engine to decide when and what to ask. This allows the system to be aware that 
the user is in a restaurant and not for example in a church, which would 
produce  totally different questions. Additionally, it enables asking 
"how was the food?", for example, at the right moment, when the user has 
already eaten in a restaurant, and not when he or she has just arrived there.

\section{Natural Language Processing}
\label{section:bg:nlp}
To be able to use crowdsourcing and address the users in natural language, the 
KA system needs to be able to convert the logical representation of questions 
into their natural language representations. Similarly, when getting the users 
answers, these answers need to be converted to logic. In addition, to be 
able to drive a coherent conversation with the user, there needs to be some 
logic which drives the dialog and the order of the questions and responses.

\subsection{Logic to Natural Language Conversion}
Being able to convert logic that the system uses to natural language that the 
user can understand is crucial part of the presented KA approach. While this is 
in general a hard problem and still not completely solved, it is often easy to 
solve simple examples of natural language generation. In our approach, we have 
investigated two scenarios. One is using preexisting Cyc natural language 
capabilities; the other is a simple scenario that is a scaled down problem 
using Umko. Cyc has more than 90 concepts which can be applied to create 
natural language generation rules\parencite{Baxter2005}, and most of the 
predicates and concepts in the KB are annotated with the rules that instruct 
the system on how to convert them to natural language. For the missing NL 
rules and also for the new vocabulary, we extended the Cyc KB.

\subsection{Natural Language to Logic Conversion}
\label{section:bg:nlToLogic}
Due to language ambiguity, 
NL to logic conversion is a harder problem than the logic to NL
\parencite{Schneider2015} (sections \ref{section:nl} and \ref{section:cycnl}). 
Similarly, the problem is not completely solved yet, but to some extent, it is 
possible to do the simple conversion using textual patterns such us the 
ChatScript (\autoref{section:chatscript} or AIML (\autoref{section:r:aiml}). 
For our implementation, we used SCG system based on Cyc, which additionally to 
textual patterns uses 
inference to check whether the conversions make sense and is to some extent 
being able to disambiguate ambiguous conversions\parencite{Schneider2015}.
The idea behind this is explained in sections \ref{section:NLLogic} and
\ref{section:cycnl}

\subsection{Dialog Formulation Logic}
Maintaining a coherent dialog while asking and answering user questions is 
almost as important as the language generation itself. Without it, the user 
quickly loses focus, is unsure about what the question refers to, etc. 
While this is mostly the domain of purely conversational agents such as 
chat-bots\parencite{Bradesko2012}, our approach still needs to address this to 
some extent. In contrast to other approaches which use text patterns to encode 
the dialog request and responses, our dialogs are triggered by knowledge. 
This means that the system actually "understands" the request and response and 
thus provides logical sequences in the conversation. The drawback is that there
can be examples which are not covered and where the system will not be able to
respond or not being able to parse them. While this is not optimal, it is not 
very different from the current state of the art solutions.

\section{Crowdsourcing}
\label{section:bg:crowdsourcing}
While the proposed KA approach works with even a single user, it shows its 
full potential when used in the crowd-sourced setting. Crowdsourcing allows 
the system to get better knowledge coverage including specifics that only a 
subset users can provide. Additionally, it allows to double-check the answers 
entered by the user against the answers of other users. In order for the system 
to use crowdsourcing, it needs to be able to address the problems that come 
with that, which are mostly related to different opinions, deliberately entering 
wrong information, trolling and handling the temporal and time dependent 
knowledge.

\subsection{Knowledge Quality and Truth Control} 
With crowdsourcing systems, the most important and most obvious problem is 
quality control. Normally there needs to be a person or evaluation system that 
checks the quality of data returned by the crowdsourcing mechanism. For our 
KA purposes, we address quality control on two levels. First, the inference 
engine uses the existing knowledge to check whether the answers are consistent. 
Then, after the answers come through this first filter, we have two mechanisms 
that can forward the newly acquired knowledge to other users able to assess it. 
This is described in more detail in \autoref{section:crowdsourcing}.

\subsection{Handling Different Opinions}
In addition to mistakes and wrong answers, users can simply have different 
opinions about something. Since our KA system also behaves as an assistant and 
needs to be consistent towards the user, it also must handle different opinions. 
For this reason, we allow the users to have their own beliefs about the world, 
which do not affect the common knowledge base, if inconsistent with it. In this w
ay if the users lie or have different opinion about something, it will only 
affect themselves and not the rest of the users. This capability is achieved by 
arranging knowledge in a tree-like structure of contexts, where the upper 
context is not aware of the lower ones, and the knowledge in the lower tree 
levels overrides the knowledge in the upper levels. In Cyc this is a kind of 
mechanism implemented through Micro Theories (aka micro-theories, MTs)
\parencite{Kleer2013}. For the explanation of the solution refer to 
\autoref{section:crowdsourcing}. 

\subsection{Handling Temporal Knowledge and Changing Knowledge}
On top of different opinions, and deliberate and accidental mistakes in the 
KA process, an additional problem is that some knowledge that reflects the real 
world must change through time. This problem needs to be tackled from two 
perspectives. One is that the KB and inference engine need to support the 
temporal dimension of knowledge. The second is that the systems need somehow to 
capture that the change happened and data previously valid may become invalid. 
For the approach using Cyc we use the fact that Cyc supports time dependent 
knowledge through special micro-theories where the always micro-theory is the 
top-most one and the time dependent ones are connected to the top one through 
a hierarchical micro-theory structure (see section \ref{section:crowdsourcing}). 

\section{Work-flow and Scalability}
Besides the scientific challenges, we have described related to the proposed 
KA approach, in order to be able to work on a broader level, technical issues 
and scalability had to be addressed as well. The knowledge base and inference 
engine if used for common sense knowledge, tend to be quite large and resource 
hungry. Our experiments were concluded using three Cyc instances, running on 
two machines and a transcript server which is used for KB syncing on a remote 
EC2 Amazon instance. One main machine was running two instances each having 
16GB of memory. The additional machine was used mostly for testing and 
evaluation. All the three Cyc instances were synced over the EC2 
transcript server.

