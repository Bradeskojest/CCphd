%-------------------------------------------------------------------------------
% 
\chapter{Knowledge Acquisition Approach}
%-------------------------------------------------------------------------------

This chapter defines the terms, formal structure and steps that form our 
proposed KA approach. First it introduces the general architecture and 
interaction loop that defines the sequence of interactions and steps
involved in the process(\autoref{section:Architecture}). In the second part, it formalizes 
the upper ontology and logical constructs required for the KA approach 
(\hl{ref to chapter}). After that, each of the crucial steps is described in 
more detail through examples and additions to the core logical structure 
defined earlier.

\section{Architecture}
\label{section:Architecture}
The proposed KA system consists of multiple interconnected technologies and 
functionalities which we grouped into logical modules according to
the problems they are solving (as also defined in \autoref{chapter:background}). 
This was done in order to minimize the complexity, improve the maintenance 
costs and allowing switching the implementations of separate sub-modules. 
Additionally such logical grouping increases the explainability and general
understanding of the system.

\begin{figure}[htb]
	\centering
		\includegraphics[width=0.9\textwidth]{figures/architecture.png}
	\caption{General Architecture of the KA system, with an interaction loop
			 presented as arrows.}
	\label{fig:Architecture}
\end{figure}


On \autoref{fig:Architecture} these modules are represented with the boxes,
and their functionality groups are presented with the colors (see the figure
legend). Arrows represent the interaction and workflow order and initiation 
(the interaction is initiated/triggered from the origin of the arrow).

We can see that the central core of the
system is the knowledge base (modules marked in purple and letter A). The 
knowledge base consists of \emph{Upper Ontology} gluing everything together, 
\emph{Common Sense Knowledge} to be able to "understand" user's world and check
the answers for consistency, \emph{Meta Knowledge} for enabling inference about 
its internal structures, \emph{User Context KB} to hold current user context and 
\emph{Knowledge Acquisition Rules} to drive the KA process from within the KB, 
using logical inference. 

Next to the KB, is an \emph{Inference Engine} that performs inference over 
the knowledge from the KB. Its modules are represented with the red color 
and letter B. The inference engine needs to be general enough to be able to
perform over full KB, and should be capable of meta-reasoning (over the 
meta-knowledge and KA knowledge in the KB) about the KB's internal knowledge
structures. In cases when the inference engine have some missing functionalities,
some of these tasks can be supplemented by the \emph{Procdeural Support} 
module. In the proposed system, inference engine handles almost all of the 
core KA operations, which can be separated into the following modules:
\begin{itemize}
   \item \emph{Consistency Checking} module which can asses the user's answers
   and check whether they fit within the current KB knowledge.
   \item \emph{KB Placement} module which decides where into the subtree of the
   KB the answer should be placed.
   \item \emph{Querying} module, which employs the inference engine to answer
   questions that are coming from the user through NL to Logic converter.
   \item \emph{Response Formulation} module, which employs the KA meta-knowledge
   and do inference about what to say/ask next. Results of this module are then
   forwarded to the Logic to NL converter and then to the user.

\end{itemize}

Tightly integrated with the knowledge base and inference engine is a 
\emph{Crowdsourcing Module}, which monitors crowd (multipl user's) answers and 
is able to remove (or move to different contexts) the knowledge from the KB, 
based on its consistency among multiple users. If some piece of knowledge inside
the KB is questionable, the module marks it as such and then \emph{Response
Formulation} module checks with other users whether it's true or not and should
maybe be removed or only kept in the one user's part of the KB. This module is 
represented in Green color and letter F.

At the entry and exit point of the system workflow, there are NLP processing  
modules which can convert logic into the natural language and vice versa. These
modules are used for natural language communication with the users. Tese two
modules are represented in Blue and letter E.

On the side of the Figure, there is a procedural module (depicted with Orange
color and letter D), which is a normal software module (in our implementations
written in procedural programming language), which glues everything together.
It contains a web-server, authentication functionalities, machine
learning capabilities, connections to external services and context mining
and other functions that are hard to implement using just logic and inference.
This module is taking care of the interactions between submodules. 

All of the modules are triggered either through the contextual triggers 
(also internal, like when timer detects the specific hour or time of day), or
by the users. When the context changes, it causes the system to use inference
engine to figure out what to do. Usually, as a consequence it results in a 
multiple options like questions or comments. Then it picks one and sends a 
request to the user. This triggering is represented with the arrows, where the 
blue arrows represent natural language interaction, and the orange one
represents structured or procedural interaction, when the procedural module
classifies or detects any useful change in the sensor data sent into the system
py the part running on the mobile phone.

\subsection{Interaction Loop}
\label{section:interaction}
As briefly already mentioned above, besides architecture, 
\autoref{fig:Architecture} also indicates a system/user interaction loop 
represented by arrows. Orange arrow (pointing 
directly from the phone towards the system) represents the automatic interaction
or triggers that the phone (client) is sending to the system all the time. This
provides one part of the user context. After the precedural part analyses
the data (as described in \hl{ref to SPD}) and enter findings into the KB as 
context, this often triggers the system to come up with a new question, or 
context related info. Example of such a trigger is, when user changes a location
and the system figures out the name and type of the new place. On the other 
side, Blue arrows represent the Natural Language interaction which can happen
as a result of automatic context (Orange arrow), or some other reason causing new 
knowledge appearing in the KB. New knowledge can appear as a consequence of
answering a question from the same user, or some other user. This shows, how the
actual knowledge (even if entered automatically through procedural component) is
controlling the interaction, and explains how the system is initialized and how
its main pro-activity driver is implemented. Examples of such initialization
of the interaction is presented in \hl{Script 1 and Script2}. Additionally, the 
user can trigger a conversation at any point in time either by continuing the 
previous conversation or simply starting a new one. 

\begin{figure}[htb]
	\centering
		\includegraphics[width=0.9\textwidth]{figures/interactionLoop.png}
	\caption{Possible interaction types between the user and Curious Cat KA
			 System.}
	\label{fig:interaction}
\end{figure}


According to the interactions described above, the proposed KA system have two 
options for the interaction. Human to machine (HMI), when users initiate 
interaction, and machine to human (MHI), when the system initiates the 
interaction. The specifics of both, which cannot fit in 
\autoref{fig:Architecture} are explained in the following sub-sections 
\hl{4.2.1 and 4.2.2}. On top of this, the design of the system allows a novel 
type of interaction which combines multiple users and machine into one 
conversation, while presenting this to the users as a single conversation track
with the machine. This becomes useful when the system doesn't have enough
knowledge to be able to answer user's questions, but it has just enough to know
which other users to ask (i.e. when someone is asking a question about specigic
place and there is no answer in the KB, \emph{Curious Cat} can ask other users
that it knows had been there). This type of the interaction can be called
Machine Mediated Human to Human interaction (MMHHI). This allows the system
to answer questions also when it doesn't know them, while simultaneously also
store and remember the answers, either parsing them and assert them directly to 
KB, or leave them in NL for later Knowledge Mining analysis. The possible
interaction types are also presented on \autoref{fig:interaction}.

\subsubsection{Machine to Human Interaction (MHI)}
\label{section:mhi}
The most basic form of interaction between the CC system and the user, which
we also use the most, is when something triggers a change in the KB and 
CC decides it's the time to ask or tell something. On the 
\autoref{fig:interaction}, this is represented by the most inner loop (MHI). 
Example of this is when the context part of \emph{Procedural} module classifies
a new location and then asserts it into the KB. This then triggers Inference 
Engine which results in a new user query (same as defined in 
\hl{ref to CCWantsToAskLocation}).

\begin{equation*}
	\label{eq:ccWantsLoc}
	ccWantsToAsk(CCUser1, (userLocation(CCUser1,CCLoc1)))
\end{equation*}

This query then goes through logic to NL \hl{ref} conversion, which is then
presented to the user in NL like "Where are we? Are we at the restaurant X?".
This is represented on \autoref{fig:interaction} with a blue arrow on the
inner circle, marked with 1a. The presentation is handled by the client and 
can be in a written form, or through the text-to-speech interface. User can then 
answer this question and thus close the interaction loop (blue arrow marked with
1b), possibly causing a new one with her answer.
The intference triggering, language rules and mechanisms for context detection
are described in more detail in sections \hl{ref, ref, ref} respectively. This
type of the interaction is where the users answer questions and is thus part of
the main research topic of this thesis.

\subsubsection{Human to Machine Interaction (HMI)}
\label{section:hmi}
dada

\subsubsection{Machine Mediated Human to Human Interaction (MMHHI)}
\label{section:mmhhi}
dada

\section{Knowledge Base}
Internally KB has three components. The main part, which should in any real implementation of the system also be the biggest, is the common-sense knowledge and its upper ontology over which we operate. This part of the system contributes the most to the ability to check the answers for consistency. The more knowledge already exists, the easier becomes to assess the answers. The second part is the user Context KB, which stores the contextual knowledge about the user. This covers the knowledge that the user has provided about himself (section 4.4.2) and the knowledge obtained by mining raw mobile sensors (section 4.4.1). This is represented as the orange arrow, pointing into the context part of the KB. The sensor based context allows the system to proactively target the right users at the right time and thus improve the efficiency and accuracy and also stickiness of the KA process.The third KB part, is the meta-knowledge and KA rules that drive the dialog and knowledge acquisition process (section 4.3.3). Although in our implementation we used Cyc KB and tested Umko KB, the approach is not fixed to any particular knowledge base. But it needs to be expressive enough to be able to cover the intended knowledge acquisition tasks and meta-knowledge needed for the system?s internal workings. After the KB, the second most important part of the architecture is an inference engine (in Fig. 2 marked in red and letter B), which is tightly connected to the knowledge base.  The inference engine needs to be able to operate with the concepts, assertions and rules from the KB and should also be capable of meta-reasoning about the knowledge base?s internal knowledge structures. As the individual components (indicated with red color in Fig. 2) suggest, the inference engine is used for:?	Checking the consistency of the users? answers (e.g., can you order a car in a restaurant if it?s not food?). ?	Placement of new knowledge inside the KB.?	Querying the KB to answer possible questions.?	Using knowledge and meta-rules to produce responses based on the user and her/his context input (similar in function to the scripts in script-based conversational agents).

Fig. 2. General Architecture of the KA system, with a simple interaction loopAt both ends of the stacked chain in Fig. 2, there are natural language processing components (marked in blue and with letter E), which are responsible for logic-to-language and language-to-logic conversion (sections 2.4 and 4.5). These are crucial if we want to interact with users in a natural way and thus avoid the need for users to be experts in first order logic. This module and its components are described in more detail in section 4.5.  Besides the main interaction loop, which implicitly uses crowdsourcing while it interacts with the users, there is an additional component (marked in green and with letter F). This ?crowdsourcing and voting? component handles and decides, which elements of knowledge (logical assertions) can be safely asserted and made ?visible? to all the users and which are questionable and should stay visible only to the authors of the knowledge. If the piece of knowledge is questionable, the system marks it as such and then the question formulation process will check with other users whether it?s true or not. This is described in more detail in section 4.7.In addition to logic-based components presented above, there is a functional driver system (marked in orange), which glues everything together, forwards the results of inference to the NL converters, accepts and asserts the context into the KB, handles the synchronization between the instances of the systems, etc.
