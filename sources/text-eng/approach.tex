%-------------------------------------------------------------------------------
% 
\chapter{Knowledge Acquisition Approach}
%-------------------------------------------------------------------------------

This chapter defines the terms, formal structure and steps that form our 
proposed KA approach. First it introduces the general architecture and 
interaction loop that defines the sequence of interactions and steps
involved in the process(\autoref{section:Architecture}). In the second part, it formalizes 
the upper ontology and logical constructs required for the KA approach 
(\hl{ref to chapter}). After that, each of the crucial steps is described in 
more detail through examples and additions to the core logical structure 
defined earlier.

\section{Architecture}
\label{section:Architecture}
The proposed KA system consists of multiple interconnected technologies and 
functionalities which we grouped into logical modules according to
the problems they are solving (as also defined in \autoref{chapter:background}). 
This was done in order to minimize the complexity, improve the maintenance 
costs and allowing switching the implementations of separate sub-modules. 
Additionally such logical grouping increases the explainability and general
understanding of the system.

\begin{figure}[htb]
	\centering
		\includegraphics[width=0.9\textwidth]{figures/architecture.png}
	\caption{General Architecture of the KA system, with an interaction loop
			 presented as arrows.}
	\label{fig:Architecture}
\end{figure}


On \autoref{fig:Architecture} these modules are represented with the boxes,
and their functionality groups are presented with the colors (see the figure
legend). Arrows represent the interaction and workflow order and initiation 
(the interaction is initiated/triggered from the origin of the arrow).

We can see that the central core of the
system is the knowledge base (modules marked in purple and letter A). The 
knowledge base consists of \emph{Upper Ontology} gluing everything together, 
\emph{Common Sense Knowledge} to be able to "understand" user's world and check
the answers for consistency, \emph{Meta Knowledge} for enabling inference about 
its internal structures, \emph{User Context KB} to hold current user context and 
\emph{Knowledge Acquisition Rules} to drive the KA process from within the KB, 
using logical inference. 

Next to the KB, is an \emph{Inference Engine} that performs inference over 
the knowledge from the KB. Its modules are represented with the red color 
and letter B. The inference engine needs to be general enough to be able to
perform over full KB, and should be capable of meta-reasoning (over the 
meta-knowledge and KA knowledge in the KB) about the KB's internal knowledge
structures. In cases when the inference engine have some missing functionalities,
some of these tasks can be supplemented by the \emph{Procdeural Support} 
module. In the proposed system, inference engine handles almost all of the 
core KA operations, which can be separated into the following modules:
\begin{itemize}
   \item \emph{Consistency Checking} module which can asses the user's answers
   and check whether they fit within the current KB knowledge.
   \item \emph{KB Placement} module which decides where into the subtree of the
   KB the answer should be placed.
   \item \emph{Querying} module, which employs the inference engine to answer
   questions that are coming from the user through NL to Logic converter.
   \item \emph{Response Formulation} module, which employs the KA meta-knowledge
   and do inference about what to say/ask next. Results of this module are then
   forwarded to the Logic to NL converter and then to the user.

\end{itemize}

Tightly integrated with the knowledge base and inference engine is a 
\emph{Crowdsourcing Module}, which monitors crowd (multipl user's) answers and 
is able to remove (or move to different contexts) the knowledge from the KB, 
based on its consistency among multiple users. If some piece of knowledge inside
the KB is questionable, the module marks it as such and then \emph{Response
Formulation} module checks with other users whether it's true or not and should
maybe be removed or only kept in the one user's part of the KB. This module is 
represented in Green color and letter F.

At the entry and exit point of the system workflow, there are NLP processing  
modules which can convert logic into the natural language and vice versa. These
modules are used for natural language communication with the users. Tese two
modules are represented in Blue and letter E.

On the side of the Figure, there is a procedural module (depicted with Orange
color and letter D), which is a normal software module (in our implementations
written in procedural programming language), which glues everything together.
It contains a web-server, authentication functionalities, machine
learning capabilities, connections to external services and context mining
and other functions that are hard to implement using just logic and inference.
This module is taking care of the interactions between submodules. 

All of the modules are triggered either through the contextual triggers 
(also internal, like when timer detects the specific hour or time of day), or
by the users. When the context changes, it causes the system to use inference
engine to figure out what to do. Usually, as a consequence it results in a 
multiple options like questions or comments. Then it picks one and sends a 
request to the user. This triggering is represented with the arrows, where the 
blue arrows represent natural language interaction, and the orange one
represents structured or procedural interaction, when the procedural module
classifies or detects any useful change in the sensor data sent into the system
py the part running on the mobile phone.

\subsection{Interaction Loop}
\label{section:interaction}
As briefly already mentioned above, besides architecture, 
\autoref{fig:Architecture} also indicates a system/user interaction loop 
represented by arrows. Orange arrow (pointing 
directly from the phone towards the system) represents the automatic interaction
or triggers that the phone (client) is sending to the system all the time. This
provides one part of the user context. After the precedural part analyses
the data (as described in \hl{ref to SPD}) and enter findings into the KB as 
context, this often triggers the system to come up with a new question, or 
context related info. Example of such a trigger is, when user changes a location
and the system figures out the name and type of the new place. On the other 
side, Blue arrows represent the Natural Language interaction which can happen
as a result of automatic context (Orange arrow), or some other reason causing new 
knowledge appearing in the KB. New knowledge can appear as a consequence of
answering a question from the same user, or some other user. This shows, how the
actual knowledge (even if entered automatically through procedural component) is
controlling the interaction, and explains how the system is initialized and how
its main pro-activity driver is implemented. Examples of such initialization
of the interaction is presented in \hl{Script 1 and Script2}. Additionally, the 
user can trigger a conversation at any point in time either by continuing the 
previous conversation or simply starting a new one. 

\begin{figure}[htb]
	\centering
		\includegraphics[width=0.9\textwidth]{figures/interactionLoop.png}
	\caption{Possible interaction types between the user and Curious Cat KA
			 System.}
	\label{fig:interaction}
\end{figure}


According to the interactions described above, the proposed KA system have two 
options for the interaction. Human to machine (HMI), when users initiate 
interaction, and machine to human (MHI), when the system initiates the 
interaction. The specifics of both, which cannot fit in 
\autoref{fig:Architecture} are explained in the following sub-sections 
\hl{4.2.1 and 4.2.2}. On top of this, the design of the system allows a novel 
type of interaction which combines multiple users and machine into one 
conversation, while presenting this to the users as a single conversation track
with the machine. This becomes useful when the system doesn't have enough
knowledge to be able to answer user's questions, but it has just enough to know
which other users to ask (i.e. when someone is asking a question about specigic
place and there is no answer in the KB, \emph{Curious Cat} can ask other users
that it knows had been there). This type of the interaction can be called
Machine Mediated Human to Human interaction (MMHHI). This allows the system
to answer questions also when it doesn't know them, while simultaneously also
store and remember the answers, either parsing them and assert them directly to 
KB, or leave them in NL for later Knowledge Mining analysis. The possible
interaction types are also presented on \autoref{fig:interaction}.

\subsubsection{Machine to Human Interaction (MHI)}
\label{section:mhi}
The most basic form of interaction between the CC system and the user, which
we also use the most, is when something triggers a change in the KB and 
CC decides it's the time to ask or tell something. On the 
\autoref{fig:interaction}, this is represented by the most inner loop (MHI). 
Example of this is when the context part of \emph{Procedural} module classifies
a new location and then asserts it into the KB. This then triggers Inference 
Engine which results in a new user query (same as defined in 
\hl{ref to CCWantsToAskLocation}).

\begin{equation*}
	\label{eq:ccWantsLoc}
	ccWantsToAsk(CCUser1, (userLocation(CCUser1,CCLoc1)))
\end{equation*}

This query then goes through logic to NL \hl{ref} conversion, which is then
presented to the user in NL like "Where are we? Are we at the restaurant X?".
This is represented on \autoref{fig:interaction} with a blue arrow on the
inner circle, marked with 1a. The presentation is handled by the client and 
can be in a written form, or through the text-to-speech interface. User can then 
answer this question and thus close the interaction loop (blue arrow marked with
1b), possibly causing a new one with her answer. 

For easier answering, the KA system can use existing KB to generate a set of 
possible answers at the qustion generation time. These can be then picked by
the user instead of writing. THe guidance can consis of variations of these:
\begin{itemize}
	\item A fixed set of pre-defined options that user can pick from, generated
	from the KB.
	\item A set of pre-defined options with an additional free text field when
	the set of possible answers is big or inifite. In this cases the text field
	is connected to the KB providing auto-complete options for valid answers.
	\item Completely free text were user can write anything. This is essentially
	the same as for the HMI interaction described below (\autoref{section:hmi}).
\end{itemize}

The example of mediated answer guidance can be seen in \hl{Fig. 3}, where the 
system presented a set of possible answers while still allowing a free text 
which will be autocompleted with the food types that the system knows about. 
If the user enters something new, the system will accept that (\hl{as was shown 
in the step 6 in Table I)}.

The inference triggering, language rules and mechanisms for context detection
are described in more detail in sections \hl{ref, ref, ref} respectively. This
type of the interaction is where the users answer questions and is thus part of
the main research topic of this thesis.

\subsubsection{Human to Machine Interaction (HMI)}
\label{section:hmi}
The second type of interaction is, when user initiates the conversation. 
If this is done at some point as the answer to an old question, the process is 
the same as described above in \autoref{section:mhi}. But users can also enter a 
free text, asking a question or stating something. In this case, this goes 
through the \emph{NL to Logic Converter} module which tries to convert the
text into logical query or assertion. The complexity of converting NL into logic 
is a lot higher than in the opposite direction, since the language is not
as exact. In CC implementation \hl{ref to CC converter}, we handled this to
some extent by using SCG system \parencite{Schneider2015}, where the text
is matched to NL patterns which are linked to appropriate logical structures.
\hl{This would be used for example, when user, instead of simple Pizza Deluxe 
(step 5 in Table I), would say They sell pizzas or something even more complex 
(see section 4.5.2)}. After the text is converted into logic, inference engine 
can use it to query it against the KB, and show the answers back to user, again 
converted into NL through \emph{Logic to NL Converter} module. This type of
interaction is depicted on \autoref{fig:interaction} by the middle arrow circle
started by humans (arrow 2a), where machine provides the response (arrow 2b).

\subsubsection{Machine Mediated Human to Human Interaction (MMHHI)}
\label{section:mmhhi}
Both of the interactions described in sections \ref{section:mhi} and 
\ref{section:hmi} pre-supposes that the receipient of the query, knows how to
answer it, or respond otherwise. In the cases when, let's say machine doesn't
have any answer (The NL question gets converted into the logical query, which doesn't retrieve any aswers from within the KB). It could respond with 
"I don't know", which is a valid response.
Thile this allows for the conversation to continue, it doesn't help the user
to get the answer, also does not benefit to knowledge acquisition. The only 
thing the system can learn from this, is that user is interested in the object
of the question. This doesn't have to end there though, since CC has access to
other users and knowledge about their past and current contexts. Based on the
topic of interes from the user query, the system can easily find users which
might know the answer (inferred from their past whereabouts, answers, etc.).
Once such an user is deteced, the original question can simply be forwarded to
him, as it would be asked by CC itself. Once he, or one of the users answers,
CC can forward it to the original user. On top of that, CC can parse the answer
the same way as described above for HMI and MHI (sections \ref{section:mhi},
\ref{section:hmi}), and remember it, placing it into the KB. In the cases when
the language of the answer is too complex, it can be stored in its original
format, for later text-mining apporach which can lead to learning of new-patterns
as well as the knowledge hiding in the answers. On top of this, CC can also
remember the question itself, and place it on specific type of concepts, as an
important quetsion to ask. On \autoref{fig:interaction},
MMHHI approach is depicted by the outer circle of arrows, where 3a is original 
user's question, which is forwarded to other users when CC doesn't know how to 
answer (3b). After one or more of the users answer, the answer is forwarded back
to the original user (3c).

\section{Knowledge Base}
As visible in \autoref{fig:Architecture}, Knowledge Base is the central part
of the proposed KA system. Internally KB has three components. The main part, 
which should in any real implementation of the system also be the biggest, is 
the common-sense knowledge, and its upper ontology over which we operate. 
This part of the system contributes the most to the ability to check the 
answers for consistency. The more knowledge already exists, the easier becomes 
to assess the answers, come up with new questions and also propose possible
answers in the guided interaction(\hl{ref}).

The second part is the user Context KB, which stores the contextual knowledge 
about the user. This covers the knowledge that the user has provided about 
himself (\hl{ref}) and the knowledge obtained by mining raw mobile sensors 
(\hl{ref}). On \autoref{fig:Architecture}, This part of the KB is represented 
as the left-most KB, sitting between the main KB and the 
\emph{Procedural Module}.The sensor based context allows the system to 
proactively target the right users at the right time and thus improve the 
efficiency and accuracy and also stickiness of the KA process.

The third KB part, is the meta-knowledge and KA rules that drive the dialog and 
knowledge acquisition process (\hl{ref}). Although in our implementation we 
used Cyc KB (\hl{ref} and also tested Umko KB (\hl{ref}), the approach is not 
fixed to any particular knowledge base. But the KB needs needs to be expressive
enough to be able to cover the intended knowledge acquisition tasks and 
meta-knowledge needed for the system's internal workings. 

Because the full Curious Cat system including the KB is too big and complex to 
be fully explained here (the KA Meta Knowledge alone consists of 12,353 
assertions and rules), we will focus on the fundamentals of the idea and 
approach, and define the simplest possible logic to explain the workings 
through the examples given in the \hl{ref} and  \hl{ref Table II}. 

The logic examples are given in formal higher order predicate logic, which we 
later replace with a more compact notation, with a slight change in the way the 
variables are presented. For better readability, instead of $x, y, z$, we mark 
variables with a question mark ($?$) followed by a name that represents the 
expected type of the concepts the variable represents. For example, when we see 
a variable in a logical formula like $CCUser(?PERSON)$, we immediately know that
$?PERSON$ can be only replaced with (bound to) instance or subclasses of the 
concept $Person$. We start predicate names with a small letter 
($predicate$) and the rest of the 
concepts with a capital letter ($Concept$). At this point it is worth noting 
that while our logical definitions and formalization are strongly influenced by 
Cyc\parencite{Lenat1995}, and while the approach is based on the Cyc upper 
ontology, the approach is general and not bound to any particular 
implementation, and our notation below reflects but is not tightly bound to 
that of OpenCyc. \todo{Add footnotes as in the paper}

\subsection{Upper Ontology}
\label{section:upperOnto}
First we introduce the vocabulary or terms (constants/concepts) that will allow 
us to construct the upper ontology which is the glue of any knowledge base that 
can be used for machine inference:
\begin{equation}
S_{Constants} = \{Something, Class, Predicate, subclass, is, arity, argClass, 
aargIs\}
\end{equation}

In the standard \emph{predicate logic}, $P(x)$ notation tells us that whathever 
the $x$ stands for, it has the property defined by the predicate $P$. 
For example, the following propositional function:
\begin{equation}\label{eq:examplepred}
Person(x)
\end{equation}
is stating that something ($x$) is a person, or more precisely, $x$ is an 
instance of a class $Person$. In order to be able to construct logical 
statements ranging
over classes and their instances in a more controlled and transparent way, we
use a constant $is$, and define it as a predicate denoting that something is an
instance of some class.
\begin{definition}[predicate "$is$"]
\label{const:is}
Predicate $is(x,y)$ denotes that $x$ is an instance of $y$.
\end{definition}
Now, to make things clearer and more precise, instead of writing instance
relation through custom predicate $Person(x)$, we can use more precise syntax, 
which allow us to specify what is instance of which class: $is(x,Person)$.

As visible in the \autoref{eq:examplepred}, in predicate logic, predicates are
defined only with usage. Everything that we write as a predicate in a similar
formula is then defined as a predicate. This is not a desired behavior in our 
KA approach, since the knowledge will be coming from the users with various
backgrounds and without any idea of predicate logic. For this reason we
need more control of what can be used where, if we want to be able to
check for consistencies and have control of our KB with the inference engine.
For this reason, we enforce a constraint (rule).

\begin{definition}[Predicate Constraint]
Everything that we want to use in the KB as a predicate, must first be defined
as an instance of the $Predicate$ class:
$\forall x \in S_{Predicates}: is(x,Predicate)$.
\end{definition}

tBW.
